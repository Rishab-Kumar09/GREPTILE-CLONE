{
  "metadata": {
    "fileName": "lambda-function-enhanced.js",
    "fileType": "react",
    "analyzedAt": "2025-09-08T22:35:46.860Z",
    "fileSize": 95815,
    "numberOfLines": 2754
  },
  "rawAiResponse": "ANALYSIS METHODOLOGY:\n1. What functions/patterns you looked at and why:\n   - I focused on functions that interact with the file system, execute shell commands, and handle user input, as these are common areas for security vulnerabilities.\n   - I also looked at functions that perform type conversions and handle external data, as these can lead to data integrity issues.\n\n2. How you analyzed each part of the code:\n   - I read through the code line by line, looking for patterns that match common vulnerabilities.\n   - I used my knowledge of JavaScript and security best practices to identify potential issues.\n\n3. What specific checks you performed:\n   - I checked for command injection in functions that execute shell commands.\n   - I looked for SQL injection vulnerabilities in database-related functions.\n   - I searched for XSS vulnerabilities in functions that handle HTML or user input.\n   - I checked for proper error handling and potential memory leaks.\n\n4. How you validated potential issues:\n   - I considered the context in which functions are used and whether user input is sanitized.\n   - I evaluated whether external data is validated before being processed.\n\n5. What criteria you used to determine severity:\n   - The impact of the vulnerability on the system's security and data integrity.\n   - The likelihood of the vulnerability being exploited.\n   - The ease with which the vulnerability can be fixed.\n\nDETAILED FINDINGS:\n1. Any patterns or issues discovered:\n   - Potential command injection via execSync usage.\n   - Possible SQL injection in database-related functions.\n   - Potential XSS vulnerabilities in functions handling HTML.\n   - Lack of error handling in asynchronous operations.\n\n2. Why they are or aren't critical:\n   - Command injection is critical because it allows arbitrary code execution.\n   - SQL injection is critical due to the risk of data loss or unauthorized access.\n   - XSS is critical as it can lead to data theft or account compromise.\n   - Missing error handling is critical as it can lead to silent failures and system instability.\n\n3. Your confidence level in each finding:\n   - High confidence in the command injection and SQL injection findings due to clear patterns.\n   - Medium confidence in the XSS findings as they require specific user input to be exploited.\n   - High confidence in the missing error handling due to the absence of catch blocks.\n\n4. Specific code examples:\n   - Command injection: execSync usage without proper input sanitization.\n   - SQL injection: Database query construction with string concatenation.\n   - XSS: Usage of innerHTML without sanitization.\n   - Missing error handling: Promises without catch blocks.\n\nFINAL RESULTS:\n- The analysis revealed several critical security vulnerabilities, including command injection, SQL injection, and XSS.\n- The code also contains critical logic errors due to missing error handling in asynchronous operations.\n- The severity of these issues is high, and they require immediate attention.\n\nREPLICATION GUIDE:\n1. How would you replicate this exact analysis WITHOUT using AI?\n   - Manually read through the code, focusing on functions that interact with the file system, execute shell commands, or handle user input.\n   - Use regular expressions to search for patterns that match common vulnerabilities.\n\n2. What specific regex patterns, AST traversals, or code checks would you implement?\n   - Regex patterns for detecting command injection: /execSync\\(.*\\)/\n   - Regex patterns for detecting SQL injection: /query.*\\+.*[\"']/\n   - Regex patterns for detecting XSS: /innerHTML\\s*=/\n   - AST traversal to check for missing catch blocks in promise chains.\n\n3. Provide a step-by-step algorithm or pseudo-code for each type of check:\n   - For each file, split the content into lines.\n   - For each line, apply the regex patterns to check for vulnerabilities.\n   - If a pattern matches, record the line number and the issue.\n   - After processing all lines, report the findings.\n\n4. Include a logic diagram or flowchart showing how the checks should be connected:\n   - Start -> Read File -> Split into Lines -> Apply Regex Patterns -> Record Issues -> Report Findings -> End\n\n5. List any edge cases that automated checks should handle:\n   - Valid command execution that looks like command injection.\n   - Legitimate database queries that resemble SQL injection patterns.\n   - Safe usage of innerHTML that is not actually vulnerable to XSS.\n   - Promises that are intentionally left without catch blocks for specific reasons.\n\nOPTIMIZATION GUIDE:\n1. How to avoid over-analysis and false positives when checking this type of file:\n   - Focus on areas of the code that interact with external systems or handle user input.\n   - Use context-aware checks to differentiate between legitimate usage and actual vulnerabilities.\n\n2. What patterns are safe to ignore vs what needs deep inspection:\n   - Ignore patterns that are commented out or part of documentation.\n   - Deeply inspect patterns that involve dynamic data or user input.\n\n3. How to handle files with no context about the rest of the repo:\n   - Treat each file as potentially critical and perform all checks unless there is clear evidence that the file is not security-sensitive.\n\n4. What confidence thresholds to use for different types of issues:\n   - Use a high confidence threshold for issues that can lead to direct system compromise, such as command injection.\n   - Use a medium confidence threshold for issues that require specific conditions to be exploited, like XSS.\n\n5. How to prioritize which files to analyze first in a large repo:\n   - Prioritize files based on their criticality, such as those handling authentication, user data, or system commands.\n\n6. What specific checks to skip if we're optimizing for speed AND accuracy:\n   - Skip checks for patterns that are highly unlikely to be vulnerabilities, such as those found in test files or known safe libraries.",
  "processedResult": {
    "fileName": "lambda-function-enhanced.js",
    "analysis": {
      "rawResponse": "ANALYSIS METHODOLOGY:\n1. What functions/patterns you looked at and why:\n   - I focused on functions that interact with the file system, execute shell commands, and handle user input, as these are common areas for security vulnerabilities.\n   - I also looked at functions that perform type conversions and handle external data, as these can lead to data integrity issues.\n\n2. How you analyzed each part of the code:\n   - I read through the code line by line, looking for patterns that match common vulnerabilities.\n   - I used my knowledge of JavaScript and security best practices to identify potential issues.\n\n3. What specific checks you performed:\n   - I checked for command injection in functions that execute shell commands.\n   - I looked for SQL injection vulnerabilities in database-related functions.\n   - I searched for XSS vulnerabilities in functions that handle HTML or user input.\n   - I checked for proper error handling and potential memory leaks.\n\n4. How you validated potential issues:\n   - I considered the context in which functions are used and whether user input is sanitized.\n   - I evaluated whether external data is validated before being processed.\n\n5. What criteria you used to determine severity:\n   - The impact of the vulnerability on the system's security and data integrity.\n   - The likelihood of the vulnerability being exploited.\n   - The ease with which the vulnerability can be fixed.\n\nDETAILED FINDINGS:\n1. Any patterns or issues discovered:\n   - Potential command injection via execSync usage.\n   - Possible SQL injection in database-related functions.\n   - Potential XSS vulnerabilities in functions handling HTML.\n   - Lack of error handling in asynchronous operations.\n\n2. Why they are or aren't critical:\n   - Command injection is critical because it allows arbitrary code execution.\n   - SQL injection is critical due to the risk of data loss or unauthorized access.\n   - XSS is critical as it can lead to data theft or account compromise.\n   - Missing error handling is critical as it can lead to silent failures and system instability.\n\n3. Your confidence level in each finding:\n   - High confidence in the command injection and SQL injection findings due to clear patterns.\n   - Medium confidence in the XSS findings as they require specific user input to be exploited.\n   - High confidence in the missing error handling due to the absence of catch blocks.\n\n4. Specific code examples:\n   - Command injection: execSync usage without proper input sanitization.\n   - SQL injection: Database query construction with string concatenation.\n   - XSS: Usage of innerHTML without sanitization.\n   - Missing error handling: Promises without catch blocks.\n\nFINAL RESULTS:\n- The analysis revealed several critical security vulnerabilities, including command injection, SQL injection, and XSS.\n- The code also contains critical logic errors due to missing error handling in asynchronous operations.\n- The severity of these issues is high, and they require immediate attention.\n\nREPLICATION GUIDE:\n1. How would you replicate this exact analysis WITHOUT using AI?\n   - Manually read through the code, focusing on functions that interact with the file system, execute shell commands, or handle user input.\n   - Use regular expressions to search for patterns that match common vulnerabilities.\n\n2. What specific regex patterns, AST traversals, or code checks would you implement?\n   - Regex patterns for detecting command injection: /execSync\\(.*\\)/\n   - Regex patterns for detecting SQL injection: /query.*\\+.*[\"']/\n   - Regex patterns for detecting XSS: /innerHTML\\s*=/\n   - AST traversal to check for missing catch blocks in promise chains.\n\n3. Provide a step-by-step algorithm or pseudo-code for each type of check:\n   - For each file, split the content into lines.\n   - For each line, apply the regex patterns to check for vulnerabilities.\n   - If a pattern matches, record the line number and the issue.\n   - After processing all lines, report the findings.\n\n4. Include a logic diagram or flowchart showing how the checks should be connected:\n   - Start -> Read File -> Split into Lines -> Apply Regex Patterns -> Record Issues -> Report Findings -> End\n\n5. List any edge cases that automated checks should handle:\n   - Valid command execution that looks like command injection.\n   - Legitimate database queries that resemble SQL injection patterns.\n   - Safe usage of innerHTML that is not actually vulnerable to XSS.\n   - Promises that are intentionally left without catch blocks for specific reasons.\n\nOPTIMIZATION GUIDE:\n1. How to avoid over-analysis and false positives when checking this type of file:\n   - Focus on areas of the code that interact with external systems or handle user input.\n   - Use context-aware checks to differentiate between legitimate usage and actual vulnerabilities.\n\n2. What patterns are safe to ignore vs what needs deep inspection:\n   - Ignore patterns that are commented out or part of documentation.\n   - Deeply inspect patterns that involve dynamic data or user input.\n\n3. How to handle files with no context about the rest of the repo:\n   - Treat each file as potentially critical and perform all checks unless there is clear evidence that the file is not security-sensitive.\n\n4. What confidence thresholds to use for different types of issues:\n   - Use a high confidence threshold for issues that can lead to direct system compromise, such as command injection.\n   - Use a medium confidence threshold for issues that require specific conditions to be exploited, like XSS.\n\n5. How to prioritize which files to analyze first in a large repo:\n   - Prioritize files based on their criticality, such as those handling authentication, user data, or system commands.\n\n6. What specific checks to skip if we're optimizing for speed AND accuracy:\n   - Skip checks for patterns that are highly unlikely to be vulnerabilities, such as those found in test files or known safe libraries.",
      "explanation": [
        "ANALYSIS METHODOLOGY:",
        "1. What functions/patterns you looked at and why:",
        "- I focused on functions that interact with the file system, execute shell commands, and handle user input, as these are common areas for security vulnerabilities.",
        "- I also looked at functions that perform type conversions and handle external data, as these can lead to data integrity issues.",
        "2. How you analyzed each part of the code:",
        "- I read through the code line by line, looking for patterns that match common vulnerabilities.",
        "- I used my knowledge of JavaScript and security best practices to identify potential issues.",
        "3. What specific checks you performed:",
        "- I checked for command injection in functions that execute shell commands.",
        "- I looked for SQL injection vulnerabilities in database-related functions.",
        "- I searched for XSS vulnerabilities in functions that handle HTML or user input.",
        "- I checked for proper error handling and potential memory leaks.",
        "4. How you validated potential issues:",
        "- I considered the context in which functions are used and whether user input is sanitized.",
        "- I evaluated whether external data is validated before being processed.",
        "5. What criteria you used to determine severity:",
        "- The impact of the vulnerability on the system's security and data integrity.",
        "- The likelihood of the vulnerability being exploited.",
        "- The ease with which the vulnerability can be fixed.",
        "DETAILED FINDINGS:",
        "1. Any patterns or issues discovered:",
        "- Potential command injection via execSync usage.",
        "- Possible SQL injection in database-related functions.",
        "- Potential XSS vulnerabilities in functions handling HTML.",
        "- Lack of error handling in asynchronous operations.",
        "2. Why they are or aren't critical:",
        "- Command injection is critical because it allows arbitrary code execution.",
        "- SQL injection is critical due to the risk of data loss or unauthorized access.",
        "- XSS is critical as it can lead to data theft or account compromise.",
        "- Missing error handling is critical as it can lead to silent failures and system instability.",
        "3. Your confidence level in each finding:",
        "- High confidence in the command injection and SQL injection findings due to clear patterns.",
        "- Medium confidence in the XSS findings as they require specific user input to be exploited.",
        "- High confidence in the missing error handling due to the absence of catch blocks.",
        "4. Specific code examples:",
        "- Command injection: execSync usage without proper input sanitization.",
        "- SQL injection: Database query construction with string concatenation.",
        "- XSS: Usage of innerHTML without sanitization.",
        "- Missing error handling: Promises without catch blocks.",
        "FINAL RESULTS:",
        "- The analysis revealed several critical security vulnerabilities, including command injection, SQL injection, and XSS.",
        "- The code also contains critical logic errors due to missing error handling in asynchronous operations.",
        "- The severity of these issues is high, and they require immediate attention.",
        "REPLICATION GUIDE:",
        "1. How would you replicate this exact analysis WITHOUT using AI?",
        "- Manually read through the code, focusing on functions that interact with the file system, execute shell commands, or handle user input.",
        "- Use regular expressions to search for patterns that match common vulnerabilities.",
        "2. What specific regex patterns, AST traversals, or code checks would you implement?",
        "- Regex patterns for detecting command injection: /execSync\\(.*\\)/",
        "- Regex patterns for detecting SQL injection: /query.*\\+.*[\"']/",
        "- Regex patterns for detecting XSS: /innerHTML\\s*=/",
        "- AST traversal to check for missing catch blocks in promise chains.",
        "3. Provide a step-by-step algorithm or pseudo-code for each type of check:",
        "- For each file, split the content into lines.",
        "- For each line, apply the regex patterns to check for vulnerabilities.",
        "- If a pattern matches, record the line number and the issue.",
        "- After processing all lines, report the findings.",
        "4. Include a logic diagram or flowchart showing how the checks should be connected:",
        "- Start -> Read File -> Split into Lines -> Apply Regex Patterns -> Record Issues -> Report Findings -> End",
        "5. List any edge cases that automated checks should handle:",
        "- Valid command execution that looks like command injection.",
        "- Legitimate database queries that resemble SQL injection patterns.",
        "- Safe usage of innerHTML that is not actually vulnerable to XSS.",
        "- Promises that are intentionally left without catch blocks for specific reasons.",
        "OPTIMIZATION GUIDE:",
        "1. How to avoid over-analysis and false positives when checking this type of file:",
        "- Focus on areas of the code that interact with external systems or handle user input.",
        "- Use context-aware checks to differentiate between legitimate usage and actual vulnerabilities.",
        "2. What patterns are safe to ignore vs what needs deep inspection:",
        "- Ignore patterns that are commented out or part of documentation.",
        "- Deeply inspect patterns that involve dynamic data or user input.",
        "3. How to handle files with no context about the rest of the repo:",
        "- Treat each file as potentially critical and perform all checks unless there is clear evidence that the file is not security-sensitive.",
        "4. What confidence thresholds to use for different types of issues:",
        "- Use a high confidence threshold for issues that can lead to direct system compromise, such as command injection.",
        "- Use a medium confidence threshold for issues that require specific conditions to be exploited, like XSS.",
        "5. How to prioritize which files to analyze first in a large repo:",
        "- Prioritize files based on their criticality, such as those handling authentication, user data, or system commands.",
        "6. What specific checks to skip if we're optimizing for speed AND accuracy:",
        "- Skip checks for patterns that are highly unlikely to be vulnerabilities, such as those found in test files or known safe libraries."
      ],
      "hasCriticalIssues": false
    },
    "analyzedAt": "2025-09-08T22:35:46.632Z",
    "filePath": "C:\\Users\\Rishi\\Downloads\\Greptile Clone\\lambda-function-enhanced.js",
    "fileSize": 95815,
    "fileContent": "import { execSync } from 'child_process';\r\nimport { promises as fs } from 'fs';\r\nimport path from 'path';\r\n\r\nconst OPENAI_API_KEY = process.env.OPENAI_API_KEY;\r\nconsole.log('ðŸ”‘ OpenAI API Key status:', OPENAI_API_KEY ? 'FOUND' : 'MISSING');\r\n\r\n// REAL STATIC ANALYSIS: Use industry-standard tools\r\nfunction performRealAnalysis(content, filePath, tempDir) {\r\n  console.log(`ðŸŽ¯ Running REAL static analysis for: ${filePath}`);\r\n  \r\n  var issues = [];\r\n  var ext = path.extname(filePath).toLowerCase();\r\n  var fileName = path.basename(filePath);\r\n  var fullPath = path.join(tempDir, filePath);\r\n  \r\n  try {\r\n    // Write file to disk for tool analysis\r\n    var fs = require('fs').promises;\r\n    var dirPath = path.dirname(fullPath);\r\n    execSync(`mkdir -p \"${dirPath}\"`, { stdio: 'ignore' });\r\n    require('fs').writeFileSync(fullPath, content);\r\n    \r\n    // Run appropriate static analysis tool based on file type\r\n    if (['.js', '.jsx', '.ts', '.tsx'].includes(ext)) {\r\n      issues = runESLintAnalysis(fullPath, content);\r\n    } else if (['.py', '.pyx'].includes(ext)) {\r\n      issues = runPylintAnalysis(fullPath, content);\r\n    } else if (['.cpp', '.cc', '.c', '.h', '.hpp'].includes(ext)) {\r\n      issues = runCppCheckAnalysis(fullPath, content);\r\n    } else if (['.java'].includes(ext)) {\r\n      issues = runSpotBugsAnalysis(fullPath, content);\r\n    } else {\r\n      // Fallback to basic analysis for unsupported types\r\n      issues = performBasicAnalysis(content, filePath);\r\n    }\r\n    \r\n  } catch (error) {\r\n    console.warn(`âš ï¸ Real analysis failed for ${filePath}, using fallback:`, error.message);\r\n    issues = performBasicAnalysis(content, filePath);\r\n  }\r\n  \r\n  return issues;\r\n}\r\n\r\n// ESLint integration for JavaScript/TypeScript\r\nfunction runESLintAnalysis(filePath, content) {\r\n  var issues = [];\r\n  \r\n  try {\r\n    // Run ESLint with strict rules\r\n    var eslintCmd = `npx eslint --format json --no-eslintrc --config '{\r\n      \"parserOptions\": { \"ecmaVersion\": 2022, \"sourceType\": \"module\", \"ecmaFeatures\": { \"jsx\": true } },\r\n      \"env\": { \"browser\": true, \"node\": true, \"es6\": true },\r\n      \"rules\": {\r\n        \"no-eval\": \"error\",\r\n        \"no-implied-eval\": \"error\", \r\n        \"no-new-func\": \"error\",\r\n        \"no-script-url\": \"error\",\r\n        \"no-unsafe-innerhtml/no-unsafe-innerhtml\": \"error\",\r\n        \"react-hooks/exhaustive-deps\": \"error\",\r\n        \"react-hooks/rules-of-hooks\": \"error\",\r\n        \"no-unused-vars\": \"error\",\r\n        \"no-undef\": \"error\",\r\n        \"prefer-const\": \"error\",\r\n        \"no-var\": \"error\"\r\n      }\r\n    }' \"${filePath}\" 2>/dev/null || echo '[]'`;\r\n    \r\n    var result = execSync(eslintCmd, { encoding: 'utf8', stdio: 'pipe' });\r\n    var eslintResults = JSON.parse(result);\r\n    \r\n    if (eslintResults[0] && eslintResults[0].messages) {\r\n      eslintResults[0].messages.forEach(function(msg) {\r\n        issues.push({\r\n          type: msg.severity === 2 ? 'error' : 'warning',\r\n          message: msg.message,\r\n          line: msg.line,\r\n          code: content.split('\\n')[msg.line - 1] || '',\r\n          severity: msg.severity === 2 ? 'high' : 'medium',\r\n          rule: msg.ruleId\r\n        });\r\n      });\r\n    }\r\n    \r\n  } catch (error) {\r\n    console.warn(`ESLint failed for ${filePath}:`, error.message);\r\n  }\r\n  \r\n  return issues;\r\n}\r\n\r\n// Pylint integration for Python\r\nfunction runPylintAnalysis(filePath, content) {\r\n  var issues = [];\r\n  \r\n  try {\r\n    var pylintCmd = `python3 -m pylint --output-format=json --disable=all --enable=unused-import,unused-variable,undefined-variable,dangerous-default-value,eval-used \"${filePath}\" 2>/dev/null || echo '[]'`;\r\n    \r\n    var result = execSync(pylintCmd, { encoding: 'utf8', stdio: 'pipe' });\r\n    var pylintResults = JSON.parse(result);\r\n    \r\n    pylintResults.forEach(function(issue) {\r\n      issues.push({\r\n        type: issue.type,\r\n        message: issue.message,\r\n        line: issue.line,\r\n        code: content.split('\\n')[issue.line - 1] || '',\r\n        severity: issue.type === 'error' ? 'high' : 'medium',\r\n        rule: issue['message-id']\r\n      });\r\n    });\r\n    \r\n  } catch (error) {\r\n    console.warn(`Pylint failed for ${filePath}:`, error.message);\r\n  }\r\n  \r\n  return issues;\r\n}\r\n\r\n// CppCheck integration for C/C++\r\nfunction runCppCheckAnalysis(filePath, content) {\r\n  var issues = [];\r\n  \r\n  try {\r\n    var cppcheckCmd = `cppcheck --enable=all --xml --xml-version=2 \"${filePath}\" 2>&1 | grep -E '<error|<location' || echo '<results></results>'`;\r\n    \r\n    var result = execSync(cppcheckCmd, { encoding: 'utf8', stdio: 'pipe' });\r\n    \r\n    // Parse XML results (simplified)\r\n    var errorMatches = result.match(/<error[^>]*msg=\"([^\"]*)\"[^>]*line=\"([^\"]*)\"[^>]*severity=\"([^\"]*)\"/g);\r\n    \r\n    if (errorMatches) {\r\n      errorMatches.forEach(function(match) {\r\n        var msgMatch = match.match(/msg=\"([^\"]*)\"/);\r\n        var lineMatch = match.match(/line=\"([^\"]*)\"/);\r\n        var severityMatch = match.match(/severity=\"([^\"]*)\"/);\r\n        \r\n        if (msgMatch && lineMatch) {\r\n          issues.push({\r\n            type: 'cppcheck',\r\n            message: msgMatch[1],\r\n            line: parseInt(lineMatch[1]) || 1,\r\n            code: content.split('\\n')[parseInt(lineMatch[1]) - 1] || '',\r\n            severity: severityMatch && severityMatch[1] === 'error' ? 'high' : 'medium'\r\n          });\r\n        }\r\n      });\r\n    }\r\n    \r\n  } catch (error) {\r\n    console.warn(`CppCheck failed for ${filePath}:`, error.message);\r\n  }\r\n  \r\n  return issues;\r\n}\r\n\r\n// SpotBugs integration for Java\r\nfunction runSpotBugsAnalysis(filePath, content) {\r\n  // For now, fallback to basic analysis for Java\r\n  return performBasicAnalysis(content, filePath);\r\n}\r\n\r\n// Fallback basic analysis (HIGHLY SELECTIVE - only critical issues)\r\nfunction performBasicAnalysis(content, filePath) {\r\n  console.log(`ðŸ”§ Using selective fallback analysis for: ${filePath}`);\r\n  \r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  var ext = path.extname(filePath).toLowerCase();\r\n  \r\n  // Context detection\r\n  var hasAuth = /password|secret|token|jwt|auth|login/i.test(content);\r\n  var hasDatabase = /SELECT|INSERT|UPDATE|DELETE|query|sql/i.test(content);\r\n  var isReactFile = /react|jsx|usestate|useeffect|component/i.test(content) || ['.jsx', '.tsx'].includes(ext);\r\n  \r\n  lines.forEach(function(line, index) {\r\n    var lineNum = index + 1;\r\n    var trimmedLine = line.trim();\r\n    \r\n    // Skip empty lines, comments, and imports\r\n    if (!trimmedLine || trimmedLine.startsWith('//') || trimmedLine.startsWith('*') || \r\n        trimmedLine.startsWith('import') || trimmedLine.startsWith('export')) return;\r\n    \r\n    // 1. CRITICAL: Hardcoded secrets (only if auth context detected)\r\n    if (hasAuth && trimmedLine.match(/(password|secret|token|key)\\s*[=:]\\s*[\"'`][a-zA-Z0-9]{12,}[\"'`]/i)) {\r\n      issues.push({\r\n        type: 'security',\r\n        message: 'Hardcoded secret detected',\r\n        line: lineNum,\r\n        code: trimmedLine.substring(0, 80),\r\n        severity: 'critical'\r\n      });\r\n    }\r\n    \r\n    // 2. CRITICAL: SQL injection (only if database context detected)\r\n    if (hasDatabase && trimmedLine.match(/(SELECT|INSERT|UPDATE|DELETE).*\\+.*[\"'`]/i)) {\r\n      issues.push({\r\n        type: 'security',\r\n        message: 'SQL injection risk',\r\n        line: lineNum,\r\n        code: trimmedLine.substring(0, 80),\r\n        severity: 'critical'\r\n      });\r\n    }\r\n    \r\n    // 3. HIGH: Empty catch blocks (always critical)\r\n    if (trimmedLine.match(/catch\\s*\\([^)]*\\)\\s*{\\s*}$/)) {\r\n      issues.push({\r\n        type: 'error-handling',\r\n        message: 'Empty catch block',\r\n        line: lineNum,\r\n        code: trimmedLine.substring(0, 80),\r\n        severity: 'high'\r\n      });\r\n    }\r\n    \r\n    // 4. REACT-SPECIFIC: Dangerous innerHTML without sanitization\r\n    if (isReactFile && trimmedLine.match(/dangerouslySetInnerHTML.*__html:\\s*[^}]*\\+/)) {\r\n      issues.push({\r\n        type: 'security',\r\n        message: 'XSS risk in dangerouslySetInnerHTML',\r\n        line: lineNum,\r\n        code: trimmedLine.substring(0, 80),\r\n        severity: 'high'\r\n      });\r\n    }\r\n    \r\n    // 5. HIGH: Memory leaks (event listeners not removed)\r\n    if (trimmedLine.match(/addEventListener/) && !content.includes('removeEventListener')) {\r\n      issues.push({\r\n        type: 'performance',\r\n        message: 'Potential memory leak - missing removeEventListener',\r\n        line: lineNum,\r\n        code: trimmedLine.substring(0, 80),\r\n        severity: 'high'\r\n      });\r\n    }\r\n    \r\n    // 6. CRITICAL: Environment variable issues (common deployment failure)\r\n    if (trimmedLine.match(/process\\.env\\./) && !content.includes('||') && !content.includes('??')) {\r\n      issues.push({\r\n        type: 'deployment',\r\n        message: 'Missing fallback for environment variable - will crash if undefined',\r\n        line: lineNum,\r\n        code: trimmedLine.substring(0, 80),\r\n        severity: 'critical'\r\n      });\r\n    }\r\n    \r\n    // 7. HIGH: Unhandled promise rejections (silent failures)\r\n    if (trimmedLine.match(/\\.then\\(/) && !trimmedLine.includes('.catch(') && !content.includes('.catch(')) {\r\n      issues.push({\r\n        type: 'error-handling',\r\n        message: 'Unhandled promise rejection - will cause silent failures',\r\n        line: lineNum,\r\n        code: trimmedLine.substring(0, 80),\r\n        severity: 'high'\r\n      });\r\n    }\r\n    \r\n    // 8. REACT-SPECIFIC: useEffect without dependencies (more precise detection)\r\n    if (isReactFile && trimmedLine.match(/useEffect\\s*\\(\\s*\\(\\s*\\)\\s*=>\\s*{/) && \r\n        !content.includes('[]') && !trimmedLine.includes('[]') && \r\n        !trimmedLine.includes('dependencies') && !trimmedLine.includes('deps')) {\r\n      \r\n      // Additional validation: make sure it's actually a problematic useEffect\r\n      var hasStateUpdate = /setState|set[A-Z]/.test(content);\r\n      var hasAsyncOperation = /fetch|axios|setTimeout|setInterval/.test(content);\r\n      \r\n      if (hasStateUpdate || hasAsyncOperation) {\r\n        issues.push({\r\n          type: 'performance',\r\n          message: 'useEffect without dependencies may cause infinite re-renders',\r\n          line: lineNum,\r\n          code: trimmedLine.substring(0, 80),\r\n          severity: 'high'  // Reduced from critical\r\n        });\r\n      }\r\n    }\r\n    \r\n    // 9. SECURITY: Dangerous eval() usage\r\n    if (trimmedLine.match(/eval\\s*\\(/) && !trimmedLine.includes('// safe')) {\r\n      issues.push({\r\n        type: 'security',\r\n        message: 'eval() usage detected - potential code injection risk',\r\n        line: lineNum,\r\n        code: trimmedLine.substring(0, 80),\r\n        severity: 'critical'\r\n      });\r\n    }\r\n    \r\n    // 10. PERFORMANCE: Inefficient loops in large datasets\r\n    if (trimmedLine.match(/for\\s*\\([^)]*in[^)]*\\)/) && content.includes('length') && content.length > 5000) {\r\n      issues.push({\r\n        type: 'performance',\r\n        message: 'for...in loop on large dataset - consider optimization',\r\n        line: lineNum,\r\n        code: trimmedLine.substring(0, 80),\r\n        severity: 'medium'\r\n      });\r\n    }\r\n    \r\n    // 11. SECURITY: Unsafe HTML rendering\r\n    if (trimmedLine.match(/innerHTML\\s*=/) && !trimmedLine.includes('sanitize') && !trimmedLine.includes('DOMPurify')) {\r\n      issues.push({\r\n        type: 'security',\r\n        message: 'Unsafe innerHTML assignment - XSS vulnerability',\r\n        line: lineNum,\r\n        code: trimmedLine.substring(0, 80),\r\n        severity: 'high'\r\n      });\r\n    }\r\n    \r\n    // 12. CRITICAL: Null pointer dereferences in C/C++\r\n    if (['.c', '.cpp', '.cc', '.h', '.hpp'].includes(ext) && \r\n        trimmedLine.match(/\\*\\w+\\s*[=\\.]/) && !trimmedLine.includes('if') && !trimmedLine.includes('null')) {\r\n      issues.push({\r\n        type: 'security',\r\n        message: 'Potential null pointer dereference',\r\n        line: lineNum,\r\n        code: trimmedLine.substring(0, 80),\r\n        severity: 'critical'\r\n      });\r\n    }\r\n  });\r\n  \r\n  console.log(`ðŸ”§ Selective fallback found ${issues.length} critical issues (filtered out noise)`);\r\n  return issues;\r\n}\r\n\r\n// ðŸŽ¯ COMPLETE STATIC ANALYSIS ENGINE - No AI, Pure Logic\r\nasync function performSemanticBugDetection(content, filePath, repoDir) {\r\n  console.log(`ðŸ” Complete static analysis: ${filePath}`);\r\n  \r\n  // Skip analysis for non-code files that shouldn't have logic/security issues\r\n  var ext = path.extname(filePath).toLowerCase();\r\n  var fileName = path.basename(filePath).toLowerCase();\r\n  \r\n  // Skip non-code files (assets, styles, etc.)\r\n  var skipExtensions = ['.css', '.scss', '.sass', '.less', '.svg', '.png', '.jpg', '.jpeg', '.gif', '.ico', '.woff', '.woff2', '.ttf', '.eot', '.map'];\r\n  \r\n  // Skip test files, config files, and documentation (high false positive rate)\r\n  var skipPatterns = [\r\n    /test/i, /spec/i, /__tests__/i, /\\.test\\./i, /\\.spec\\./i,\r\n    /config/i, /\\.config\\./i, /webpack/i, /babel/i, /eslint/i,\r\n    /readme/i, /changelog/i, /license/i, /\\.md$/i,\r\n    /fixture/i, /mock/i, /example/i, /demo/i,\r\n    /node_modules/i, /dist/i, /build/i, /coverage/i\r\n  ];\r\n  \r\n  if (skipExtensions.includes(ext)) {\r\n    console.log(`â­ï¸ Skipping static analysis for ${ext} file: ${filePath} (non-code file)`);\r\n    return [];\r\n  }\r\n  \r\n  if (skipPatterns.some(pattern => pattern.test(filePath))) {\r\n    console.log(`â­ï¸ Skipping static analysis for: ${filePath} (test/config/docs file)`);\r\n    return [];\r\n  }\r\n  \r\n  var allIssues = [];\r\n  \r\n  // ðŸ”´ CRITICAL SECURITY CHECKS\r\n  allIssues = allIssues.concat(checkHardcodedSecrets(content, filePath));\r\n  allIssues = allIssues.concat(checkUnsafeAPIs(content, filePath));\r\n  allIssues = allIssues.concat(checkSQLInjection(content, filePath));\r\n  allIssues = allIssues.concat(checkCommandInjection(content, filePath));\r\n  allIssues = allIssues.concat(checkXSSVulnerabilities(content, filePath));\r\n  allIssues = allIssues.concat(checkInsecureOperations(content, filePath));\r\n  \r\n  // ðŸŸ  HIGH PRIORITY LOGIC CHECKS  \r\n  allIssues = allIssues.concat(checkNullDereference(content, filePath));\r\n  allIssues = allIssues.concat(checkUnhandledPromises(content, filePath));\r\n  allIssues = allIssues.concat(checkResourceLeaks(content, filePath));\r\n  allIssues = allIssues.concat(checkRaceConditions(content, filePath));\r\n  allIssues = allIssues.concat(checkErrorHandling(content, filePath));\r\n  \r\n  // âš¡ PERFORMANCE CHECKS\r\n  allIssues = allIssues.concat(checkNPlusOneQueries(content, filePath));\r\n  allIssues = allIssues.concat(checkInefficiientRegex(content, filePath));\r\n  allIssues = allIssues.concat(checkMemoryLeaks(content, filePath));\r\n  allIssues = allIssues.concat(checkPerformanceAntipatterns(content, filePath));\r\n  \r\n  // ðŸ” CODE QUALITY CHECKS\r\n  allIssues = allIssues.concat(checkComplexity(content, filePath));\r\n  allIssues = allIssues.concat(checkCodeSmells(content, filePath));\r\n  allIssues = allIssues.concat(checkBestPractices(content, filePath));\r\n  \r\n  // ðŸ”— CROSS-FILE CHECKS (when repo context available)\r\n  if (repoDir) {\r\n    allIssues = allIssues.concat(checkUnusedImports(content, filePath));\r\n    allIssues = allIssues.concat(checkImportIssues(content, filePath, repoDir));\r\n  }\r\n  \r\n  // FILTER OUT LOW SEVERITY ISSUES - Focus on what matters\r\n  var criticalIssues = allIssues.filter(issue => \r\n    issue.severity === 'critical' || issue.severity === 'high' || issue.severity === 'medium'\r\n  );\r\n  \r\n  console.log(`ðŸ” Static analysis found ${criticalIssues.length} critical/high/medium issues in ${filePath} (filtered out ${allIssues.length - criticalIssues.length} low-priority/informational noise)`);\r\n  \r\n  // Note: AI filtering now happens at batch level for efficiency\r\n  return criticalIssues;\r\n}\r\n\r\n// ðŸ¤– AI-POWERED POST-ANALYSIS FILTER\r\nasync function performAIIssueFilter(issues, content, filePath) {\r\n  if (!OPENAI_API_KEY || issues.length === 0) {\r\n    console.log('âš ï¸ Skipping AI filter: No API key or no issues');\r\n    return issues;\r\n  }\r\n  \r\n  try {\r\n    console.log(`ðŸ¤– AI filtering ${issues.length} issues in ${filePath}...`);\r\n    \r\n    // Prepare issues for AI analysis\r\n    var issuesSummary = issues.map((issue, index) => ({\r\n      id: index,\r\n      type: issue.type,\r\n      message: issue.message,\r\n      line: issue.line,\r\n      severity: issue.severity,\r\n      code: issue.code,\r\n      context: getCodeContext(content, issue.line)\r\n    }));\r\n    \r\n    var aiPrompt = `You are an expert code reviewer. Analyze these ${issues.length} potential code issues and determine which are REAL actionable problems vs false positives.\r\n\r\nFile: ${filePath}\r\nIssues found by static analysis:\r\n\r\n${issuesSummary.map(issue => \r\n`[${issue.id}] ${issue.severity.toUpperCase()}: ${issue.message}\r\nLine ${issue.line}: ${issue.code}\r\nContext: ${issue.context}\r\n`).join('\\n')}\r\n\r\nFor each issue, determine if it's:\r\n- REAL: Actual problem that needs developer attention\r\n- FALSE_POSITIVE: Static analysis mistake, not a real issue\r\n- IGNORE: Too minor/context-dependent to be actionable\r\n\r\nConsider:\r\n1. Is this a genuine security/performance/logic issue?\r\n2. Is the code pattern actually problematic in this context?\r\n3. Would a developer realistically need to fix this?\r\n4. Are there obvious false positives (e.g., test files, mock data, comments)?\r\n\r\nReturn ONLY a JSON array with issue IDs to KEEP (real issues only):\r\n[0, 2, 5, 7]`;\r\n\r\n    var response = await fetch('https://api.openai.com/v1/chat/completions', {\r\n      method: 'POST',\r\n      headers: {\r\n        'Authorization': `Bearer ${OPENAI_API_KEY}`,\r\n        'Content-Type': 'application/json'\r\n      },\r\n      body: JSON.stringify({\r\n        model: 'gpt-4o-mini',\r\n        messages: [{ role: 'user', content: aiPrompt }],\r\n        temperature: 0.1,\r\n        max_tokens: 500\r\n      })\r\n    });\r\n    \r\n    if (!response.ok) {\r\n      console.error(`âŒ AI filter API error: ${response.status}`);\r\n      return issues; // Return original issues on API failure\r\n    }\r\n    \r\n    var data = await response.json();\r\n    var aiResponse = data.choices[0].message.content.trim();\r\n    \r\n    // Parse AI response to get issue IDs to keep\r\n    var jsonMatch = aiResponse.match(/\\[[\\d,\\s]*\\]/);\r\n    if (jsonMatch) {\r\n      var idsToKeep = JSON.parse(jsonMatch[0]);\r\n      var filteredIssues = issues.filter((_, index) => idsToKeep.includes(index));\r\n      \r\n      console.log(`ðŸ¤– AI filter results: Keeping ${filteredIssues.length}/${issues.length} issues`);\r\n      console.log(`ðŸ—‘ï¸ AI removed: ${issues.length - filteredIssues.length} false positives/non-actionable issues`);\r\n      \r\n      return filteredIssues;\r\n    } else {\r\n      console.warn('âš ï¸ AI filter: Could not parse response, keeping all issues');\r\n      console.log('AI response:', aiResponse);\r\n      return issues;\r\n    }\r\n    \r\n  } catch (error) {\r\n    console.error(`âŒ AI filter failed for ${filePath}:`, error.message);\r\n    return issues; // Return original issues on error\r\n  }\r\n}\r\n\r\n// Helper function to get code context around an issue\r\nfunction getCodeContext(content, lineNumber) {\r\n  var lines = content.split('\\n');\r\n  var start = Math.max(0, lineNumber - 3);\r\n  var end = Math.min(lines.length, lineNumber + 2);\r\n  return lines.slice(start, end).map((line, i) => {\r\n    var actualLineNum = start + i + 1;\r\n    var marker = actualLineNum === lineNumber ? 'â†’ ' : '  ';\r\n    return `${marker}${actualLineNum}: ${line}`;\r\n  }).join('\\n');\r\n}\r\n\r\n// ðŸ¤– BATCH AI FILTER - Process multiple files efficiently\r\nasync function performBatchAIFilter(fileResults) {\r\n  if (!OPENAI_API_KEY || fileResults.length === 0) {\r\n    return fileResults;\r\n  }\r\n  \r\n  try {\r\n    // Process files in smaller batches to avoid token limits\r\n    var batchSize = 3; // Process 3 files at a time\r\n    var filteredResults = [];\r\n    \r\n    for (var i = 0; i < fileResults.length; i += batchSize) {\r\n      var batch = fileResults.slice(i, i + batchSize);\r\n      var batchFiltered = await processBatchFiles(batch);\r\n      filteredResults = filteredResults.concat(batchFiltered);\r\n      \r\n      console.log(`ðŸ¤– AI batch ${Math.floor(i/batchSize) + 1}/${Math.ceil(fileResults.length/batchSize)} complete`);\r\n    }\r\n    \r\n    return filteredResults;\r\n    \r\n  } catch (error) {\r\n    console.error('âŒ Batch AI filter failed:', error.message);\r\n    return fileResults; // Return original on error\r\n  }\r\n}\r\n\r\n// Process a small batch of files with AI\r\nasync function processBatchFiles(batch) {\r\n  var totalIssues = batch.reduce((sum, file) => sum + file.issues.length, 0);\r\n  \r\n  if (totalIssues === 0) {\r\n    return batch;\r\n  }\r\n  \r\n  console.log(`ðŸ¤– AI analyzing ${batch.length} files with ${totalIssues} total issues...`);\r\n  \r\n  // Create comprehensive prompt for batch analysis\r\n  var batchPrompt = `You are an expert code reviewer. Analyze these ${totalIssues} potential code issues across ${batch.length} files and identify which are REAL actionable problems vs false positives.\r\n\r\n${batch.map((fileResult, fileIndex) => \r\n`FILE ${fileIndex}: ${fileResult.file}\r\n${fileResult.issues.map((issue, issueIndex) => \r\n`[${fileIndex}.${issueIndex}] ${issue.severity.toUpperCase()}: ${issue.message}\r\nLine ${issue.line}: ${issue.code}\r\nContext: ${getCodeContext(fileResult.content, issue.line)}\r\n`).join('\\n')}\r\n`).join('\\n')}\r\n\r\nFor each issue, determine if it's:\r\n- REAL: Actual problem that needs developer attention  \r\n- FALSE_POSITIVE: Static analysis mistake (e.g., test files, mock data, comments, legitimate patterns)\r\n- IGNORE: Too minor/context-dependent to be actionable\r\n\r\nConsider:\r\n1. Is this a genuine security/performance/logic issue?\r\n2. Is the code pattern actually problematic in this context?\r\n3. Would a developer realistically need to fix this?\r\n4. Are there obvious false positives (test files, mock data, generated code)?\r\n5. Is this issue in a test file, config file, or documentation?\r\n\r\nReturn ONLY a JSON object with file indices and issue indices to KEEP:\r\n{\r\n  \"0\": [0, 2, 5],\r\n  \"1\": [1, 3],\r\n  \"2\": []\r\n}`;\r\n\r\n  try {\r\n    var response = await fetch('https://api.openai.com/v1/chat/completions', {\r\n      method: 'POST',\r\n      headers: {\r\n        'Authorization': `Bearer ${OPENAI_API_KEY}`,\r\n        'Content-Type': 'application/json'\r\n      },\r\n      body: JSON.stringify({\r\n        model: 'gpt-4o-mini',\r\n        messages: [{ role: 'user', content: batchPrompt }],\r\n        temperature: 0.1,\r\n        max_tokens: 1000\r\n      })\r\n    });\r\n    \r\n    if (!response.ok) {\r\n      console.error(`âŒ Batch AI filter API error: ${response.status}`);\r\n      return batch;\r\n    }\r\n    \r\n    var data = await response.json();\r\n    var aiResponse = data.choices[0].message.content.trim();\r\n    \r\n    // Parse AI response\r\n    var jsonMatch = aiResponse.match(/\\{[\\s\\S]*\\}/);\r\n    if (jsonMatch) {\r\n      var keepMap = JSON.parse(jsonMatch[0]);\r\n      \r\n      // Filter issues based on AI recommendations\r\n      var filteredBatch = batch.map((fileResult, fileIndex) => {\r\n        var indicesToKeep = keepMap[fileIndex.toString()] || [];\r\n        var filteredIssues = fileResult.issues.filter((_, issueIndex) => \r\n          indicesToKeep.includes(issueIndex)\r\n        );\r\n        \r\n        return {\r\n          file: fileResult.file,\r\n          issues: filteredIssues,\r\n          content: fileResult.content\r\n        };\r\n      });\r\n      \r\n      var originalCount = totalIssues;\r\n      var filteredCount = filteredBatch.reduce((sum, file) => sum + file.issues.length, 0);\r\n      \r\n      console.log(`ðŸ¤– AI batch filter: ${originalCount} â†’ ${filteredCount} issues (removed ${originalCount - filteredCount})`);\r\n      \r\n      return filteredBatch;\r\n      \r\n    } else {\r\n      console.warn('âš ï¸ Could not parse AI batch response, keeping all issues');\r\n      return batch;\r\n    }\r\n    \r\n  } catch (error) {\r\n    console.error(`âŒ Batch AI processing failed:`, error.message);\r\n    return batch;\r\n  }\r\n}\r\n\r\n// ðŸ”´ CRITICAL SECURITY FUNCTIONS\r\n\r\n// 1. HARDCODED SECRETS DETECTION\r\nfunction checkHardcodedSecrets(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  var secretPatterns = [\r\n    { pattern: /(password|pwd|pass)\\s*[:=]\\s*[\"'][^\"']{3,}[\"']/i, message: 'Hardcoded password detected' },\r\n    { pattern: /(api_?key|apikey)\\s*[:=]\\s*[\"'][^\"']{10,}[\"']/i, message: 'Hardcoded API key detected' },\r\n    { pattern: /(secret|token)\\s*[:=]\\s*[\"'][^\"']{8,}[\"']/i, message: 'Hardcoded secret/token detected' },\r\n    { pattern: /sk-[a-zA-Z0-9]{48}/i, message: 'OpenAI API key detected' },\r\n    { pattern: /ghp_[a-zA-Z0-9]{36}/i, message: 'GitHub token detected' },\r\n    { pattern: /AKIA[0-9A-Z]{16}/i, message: 'AWS access key detected' },\r\n    { pattern: /mongodb:\\/\\/[^:]+:[^@]+@/i, message: 'MongoDB connection string with credentials' },\r\n    { pattern: /postgres:\\/\\/[^:]+:[^@]+@/i, message: 'PostgreSQL connection string with credentials' }\r\n  ];\r\n  \r\n  lines.forEach((line, index) => {\r\n    secretPatterns.forEach(({ pattern, message }) => {\r\n      if (pattern.test(line)) {\r\n        issues.push({\r\n          type: 'security',\r\n          message: message + ' - use environment variables',\r\n          line: index + 1,\r\n          severity: 'critical',\r\n          code: line.replace(/[\"'][^\"']*[\"']/, '\"***REDACTED***\"'),\r\n          pattern: 'hardcoded_secret'\r\n        });\r\n      }\r\n    });\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// 2. UNSAFE APIS DETECTION  \r\nfunction checkUnsafeAPIs(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  var unsafeAPIs = [\r\n    { pattern: /eval\\s*\\(/i, message: 'eval() is dangerous - code injection vulnerability', severity: 'critical' },\r\n    { pattern: /Function\\s*\\(/i, message: 'Function() constructor allows code injection', severity: 'critical' },\r\n    { pattern: /setTimeout\\s*\\(\\s*[\"']/i, message: 'setTimeout with string is unsafe - use function', severity: 'high' },\r\n    { pattern: /setInterval\\s*\\(\\s*[\"']/i, message: 'setInterval with string is unsafe - use function', severity: 'high' },\r\n    { pattern: /document\\.write\\s*\\(/i, message: 'document.write() can cause XSS vulnerabilities', severity: 'high' },\r\n    { pattern: /innerHTML\\s*=(?!\\s*[\"'][\\s]*[\"'])/i, message: 'innerHTML assignment without sanitization - XSS risk', severity: 'high' },\r\n    { pattern: /outerHTML\\s*=/i, message: 'outerHTML assignment - XSS risk', severity: 'high' },\r\n    { pattern: /dangerouslySetInnerHTML/i, message: 'React dangerouslySetInnerHTML - ensure content is sanitized', severity: 'medium' },\r\n    { pattern: /pickle\\.loads?\\s*\\(/i, message: 'pickle.load() can execute arbitrary code', severity: 'critical' },\r\n    { pattern: /yaml\\.load\\s*\\(/i, message: 'yaml.load() without safe_load is dangerous', severity: 'critical' },\r\n    { pattern: /os\\.system\\s*\\(/i, message: 'os.system() vulnerable to command injection', severity: 'critical' },\r\n    { pattern: /shell\\s*=\\s*True/i, message: 'subprocess with shell=True enables command injection', severity: 'high' }\r\n  ];\r\n  \r\n  lines.forEach((line, index) => {\r\n    unsafeAPIs.forEach(({ pattern, message, severity }) => {\r\n      if (pattern.test(line)) {\r\n        issues.push({\r\n          type: 'security',\r\n          message: message,\r\n          line: index + 1,\r\n          severity: severity,\r\n          code: line.trim(),\r\n          pattern: 'unsafe_api'\r\n        });\r\n      }\r\n    });\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// 3. SQL INJECTION DETECTION\r\nfunction checkSQLInjection(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  lines.forEach((line, index) => {\r\n    // String concatenation in SQL queries\r\n    if ((/query|select|insert|update|delete|execute/i.test(line)) && \r\n        (/\\+.*[\"']|[\"'].*\\+|\\$\\{|\\`\\$\\{|format\\(|f[\"']/i.test(line))) {\r\n      issues.push({\r\n        type: 'security',\r\n        message: 'SQL injection risk: Use parameterized queries instead of string concatenation',\r\n        line: index + 1,\r\n        severity: 'critical',\r\n        code: line.trim(),\r\n        pattern: 'sql_injection'\r\n      });\r\n    }\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// 4. COMMAND INJECTION DETECTION\r\nfunction checkCommandInjection(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  var commandAPIs = ['exec(', 'spawn(', 'system(', 'popen(', 'subprocess.'];\r\n  \r\n  lines.forEach((line, index) => {\r\n    commandAPIs.forEach(api => {\r\n      if (line.includes(api) && (/\\+|\\$\\{|format\\(|f[\"']|\\%s|\\%d/i.test(line))) {\r\n        issues.push({\r\n          type: 'security',\r\n          message: 'Command injection risk: User input in system commands - use parameterized execution',\r\n          line: index + 1,\r\n          severity: 'critical',\r\n          code: line.trim(),\r\n          pattern: 'command_injection'\r\n        });\r\n      }\r\n    });\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// 5. XSS VULNERABILITIES\r\nfunction checkXSSVulnerabilities(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  lines.forEach((line, index) => {\r\n    // Unsafe HTML insertion\r\n    if (/innerHTML|outerHTML|insertAdjacentHTML/i.test(line) && \r\n        !/sanitize|escape|encode|textContent/i.test(line)) {\r\n      issues.push({\r\n        type: 'security',\r\n        message: 'XSS vulnerability: HTML insertion without sanitization',\r\n        line: index + 1,\r\n        severity: 'high',\r\n        code: line.trim(),\r\n        pattern: 'xss_vulnerability'\r\n      });\r\n    }\r\n    \r\n    // Direct user input in HTML\r\n    if (/\\$\\{.*input.*\\}|\\+.*input.*\\+/i.test(line) && /html|template/i.test(line)) {\r\n      issues.push({\r\n        type: 'security',\r\n        message: 'XSS risk: User input directly in HTML template',\r\n        line: index + 1,\r\n        severity: 'high',\r\n        code: line.trim(),\r\n        pattern: 'xss_vulnerability'\r\n      });\r\n    }\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// 6. INSECURE OPERATIONS\r\nfunction checkInsecureOperations(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  lines.forEach((line, index) => {\r\n    // Disabled SSL verification\r\n    if (/verify\\s*=\\s*False|VERIFY_NONE|rejectUnauthorized.*false/i.test(line)) {\r\n      issues.push({\r\n        type: 'security',\r\n        message: 'SSL verification disabled - man-in-the-middle attack risk',\r\n        line: index + 1,\r\n        severity: 'high',\r\n        code: line.trim(),\r\n        pattern: 'insecure_ssl'\r\n      });\r\n    }\r\n    \r\n    // Weak cryptographic algorithms\r\n    if (/MD5|SHA1|DES(?!C)|RC4/i.test(line) && !/SHA1[0-9]|HMAC/i.test(line)) {\r\n      issues.push({\r\n        type: 'security',\r\n        message: 'Weak cryptographic algorithm - use SHA-256 or better',\r\n        line: index + 1,\r\n        severity: 'medium',\r\n        code: line.trim(),\r\n        pattern: 'weak_crypto'\r\n      });\r\n    }\r\n    \r\n    // Insecure random number generation\r\n    if (/Math\\.random\\(\\)|random\\.random\\(\\)/i.test(line) && /token|password|key|secret/i.test(line)) {\r\n      issues.push({\r\n        type: 'security',\r\n        message: 'Insecure random generation for security purposes - use crypto.randomBytes()',\r\n        line: index + 1,\r\n        severity: 'medium',\r\n        code: line.trim(),\r\n        pattern: 'insecure_random'\r\n      });\r\n    }\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// ðŸŸ  HIGH PRIORITY LOGIC CHECKS\r\n\r\n// 7. NULL DEREFERENCE DETECTION\r\nfunction checkNullDereference(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  lines.forEach((line, index) => {\r\n    // Object method calls without null checks\r\n    if (/\\w+\\.(length|push|pop|map|filter|forEach|slice|indexOf|includes)/i.test(line)) {\r\n      var prevLines = lines.slice(Math.max(0, index - 3), index).join('\\n');\r\n      var currentAndNext = lines.slice(index, index + 2).join('\\n');\r\n      \r\n      if (!/if.*null|if.*undefined|\\?\\.|&&.*\\w+|optional|guard|check/i.test(prevLines + currentAndNext)) {\r\n        issues.push({\r\n          type: 'logic',\r\n          message: 'Potential null dereference: Check if object exists before calling methods',\r\n          line: index + 1,\r\n          severity: 'high',\r\n          code: line.trim(),\r\n          pattern: 'null_dereference'\r\n        });\r\n      }\r\n    }\r\n    \r\n    // Array/Object access without bounds checking\r\n    if (/\\w+\\[\\d+\\]|\\w+\\[.*\\]/i.test(line) && !/length|size|bounds|check/i.test(line)) {\r\n      issues.push({\r\n        type: 'logic',\r\n        message: 'Array access without bounds checking - may cause runtime errors',\r\n        line: index + 1,\r\n        severity: 'medium',\r\n        code: line.trim(),\r\n        pattern: 'bounds_check'\r\n      });\r\n    }\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// 8. UNHANDLED PROMISES DETECTION\r\nfunction checkUnhandledPromises(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  lines.forEach((line, index) => {\r\n    // Async calls without proper error handling\r\n    if (/await\\s+\\w+\\(/i.test(line)) {\r\n      var surroundingCode = lines.slice(Math.max(0, index - 5), index + 5).join('\\n');\r\n      if (!/try|catch|\\.catch\\(/i.test(surroundingCode)) {\r\n        issues.push({\r\n          type: 'logic',\r\n          message: 'Unhandled async operation: Add try-catch or .catch() for error handling',\r\n          line: index + 1,\r\n          severity: 'high',\r\n          code: line.trim(),\r\n          pattern: 'unhandled_promise'\r\n        });\r\n      }\r\n    }\r\n    \r\n    // Promise chains without catch\r\n    if (/\\.then\\s*\\(/i.test(line)) {\r\n      var nextLines = lines.slice(index, index + 5).join('\\n');\r\n      if (!/\\.catch\\s*\\(/i.test(nextLines)) {\r\n        issues.push({\r\n          type: 'logic',\r\n          message: 'Promise chain without error handling: Add .catch() block',\r\n          line: index + 1,\r\n          severity: 'medium',\r\n          code: line.trim(),\r\n          pattern: 'unhandled_promise'\r\n        });\r\n      }\r\n    }\r\n    \r\n    // Fire-and-forget async calls\r\n    if (/^\\s*\\w+\\s*\\(/i.test(line) && /async|await|Promise/i.test(line) && !/await|return|const|let|var/i.test(line)) {\r\n      issues.push({\r\n        type: 'logic',\r\n        message: 'Fire-and-forget async call: Handle the promise or mark as intentional',\r\n        line: index + 1,\r\n        severity: 'medium',\r\n        code: line.trim(),\r\n        pattern: 'fire_forget_async'\r\n      });\r\n    }\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// 9. RESOURCE LEAKS DETECTION\r\nfunction checkResourceLeaks(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  lines.forEach((line, index) => {\r\n    // File operations without proper cleanup\r\n    if (/open\\s*\\(|createReadStream|createWriteStream|fs\\.open/i.test(line)) {\r\n      var nextLines = lines.slice(index, index + 15).join('\\n');\r\n      if (!/close\\s*\\(\\)|\\.end\\s*\\(\\)|finally|with\\s+/i.test(nextLines)) {\r\n        issues.push({\r\n          type: 'logic',\r\n          message: 'Resource leak: File/stream opened but not properly closed',\r\n          line: index + 1,\r\n          severity: 'high',\r\n          code: line.trim(),\r\n          pattern: 'resource_leak'\r\n        });\r\n      }\r\n    }\r\n    \r\n    // Database connections without cleanup\r\n    if (/connect\\s*\\(|createConnection|getConnection/i.test(line)) {\r\n      var nextLines = lines.slice(index, index + 20).join('\\n');\r\n      if (!/disconnect|close|end|release|finally/i.test(nextLines)) {\r\n        issues.push({\r\n          type: 'logic',\r\n          message: 'Database connection leak: Connection not properly closed',\r\n          line: index + 1,\r\n          severity: 'high',\r\n          code: line.trim(),\r\n          pattern: 'connection_leak'\r\n        });\r\n      }\r\n    }\r\n    \r\n    // Event listeners without cleanup\r\n    if (/addEventListener|on\\s*\\(/i.test(line)) {\r\n      if (!/removeEventListener|off\\s*\\(|cleanup|unmount/i.test(content)) {\r\n        issues.push({\r\n          type: 'performance',\r\n          message: 'Memory leak: Event listener added but never removed',\r\n          line: index + 1,\r\n          severity: 'medium',\r\n          code: line.trim(),\r\n          pattern: 'memory_leak'\r\n        });\r\n      }\r\n    }\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// 10. RACE CONDITIONS DETECTION\r\nfunction checkRaceConditions(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  lines.forEach((line, index) => {\r\n    // Multiple async operations without proper synchronization\r\n    if (/Promise\\.all|Promise\\.allSettled/i.test(line)) {\r\n      var nextLines = lines.slice(index, index + 10).join('\\n');\r\n      if (/shared|global|state|variable/i.test(nextLines) && !/mutex|lock|semaphore/i.test(nextLines)) {\r\n        issues.push({\r\n          type: 'logic',\r\n          message: 'Potential race condition: Concurrent access to shared state without synchronization',\r\n          line: index + 1,\r\n          severity: 'medium',\r\n          code: line.trim(),\r\n          pattern: 'race_condition'\r\n        });\r\n      }\r\n    }\r\n    \r\n    // Global variable modifications in async context\r\n    if (/global\\.|window\\.|process\\.env/i.test(line) && /=|assign|push|pop/i.test(line)) {\r\n      var surroundingCode = lines.slice(Math.max(0, index - 3), index + 3).join('\\n');\r\n      if (/async|await|setTimeout|setInterval/i.test(surroundingCode)) {\r\n        issues.push({\r\n          type: 'logic',\r\n          message: 'Race condition risk: Global state modification in async context',\r\n          line: index + 1,\r\n          severity: 'medium',\r\n          code: line.trim(),\r\n          pattern: 'async_global_modify'\r\n        });\r\n      }\r\n    }\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// 11. ERROR HANDLING ISSUES\r\nfunction checkErrorHandling(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  lines.forEach((line, index) => {\r\n    // Empty catch blocks\r\n    if (/catch\\s*\\(\\s*\\w*\\s*\\)\\s*\\{[\\s]*\\}/i.test(line)) {\r\n      issues.push({\r\n        type: 'logic',\r\n        message: 'Empty catch block: Handle errors properly or add explanatory comment',\r\n        line: index + 1,\r\n        severity: 'high',\r\n        code: line.trim(),\r\n        pattern: 'empty_catch'\r\n      });\r\n    }\r\n    \r\n    // Catch blocks that only log\r\n    if (/catch.*\\{[\\s]*console\\.log|catch.*\\{[\\s]*logger/i.test(line)) {\r\n      var nextLines = lines.slice(index, index + 5).join('\\n');\r\n      if (!/throw|return|handle|recover/i.test(nextLines)) {\r\n        issues.push({\r\n          type: 'logic',\r\n          message: 'Error swallowing: Catch block only logs but doesn\\'t handle the error',\r\n          line: index + 1,\r\n          severity: 'medium',\r\n          code: line.trim(),\r\n          pattern: 'error_swallow'\r\n        });\r\n      }\r\n    }\r\n    \r\n    // REMOVED: Generic error messages (low severity noise)\r\n    // if (/throw.*Error\\s*\\(\\s*[\"']error|[\"']something went wrong|[\"']oops/i.test(line)) {\r\n    //   issues.push({\r\n    //     type: 'maintainability',\r\n    //     message: 'Generic error message: Provide specific, actionable error details',\r\n    //     line: index + 1,\r\n    //     severity: 'low',\r\n    //     code: line.trim(),\r\n    //     pattern: 'generic_error'\r\n    //   });\r\n    // }\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// âš¡ PERFORMANCE CHECKS\r\n\r\n// 12. N+1 QUERIES DETECTION\r\nfunction checkNPlusOneQueries(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  lines.forEach((line, index) => {\r\n    // Database queries inside loops\r\n    if (/for\\s*\\(|while\\s*\\(|\\.forEach|\\.map/i.test(line)) {\r\n      var nextLines = lines.slice(index, index + 15).join('\\n');\r\n      var queryPatterns = [\r\n        'query\\\\s*\\\\(',\r\n        'find\\\\s*\\\\(',\r\n        'findOne\\\\s*\\\\(',\r\n        'findMany\\\\s*\\\\(',\r\n        'select\\\\s*\\\\(',\r\n        'insert\\\\s*\\\\(',\r\n        'update\\\\s*\\\\(',\r\n        'delete\\\\s*\\\\(',\r\n        'execute\\\\s*\\\\(',\r\n        'fetch\\\\s*\\\\(',\r\n        'get\\\\s*\\\\(',\r\n        'post\\\\s*\\\\(',\r\n        'put\\\\s*\\\\(',\r\n        'patch\\\\s*\\\\('\r\n      ];\r\n      \r\n      queryPatterns.forEach(pattern => {\r\n        if (new RegExp(pattern, 'i').test(nextLines)) {\r\n          issues.push({\r\n            type: 'performance',\r\n            message: 'N+1 query problem: Database/API query inside loop - use batch operations',\r\n            line: index + 1,\r\n            severity: 'high',\r\n            code: line.trim(),\r\n            pattern: 'n_plus_one'\r\n          });\r\n        }\r\n      });\r\n    }\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// 13. INEFFICIENT REGEX DETECTION\r\nfunction checkInefficiientRegex(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  var dangerousPatterns = [\r\n    { pattern: /\\/.*\\(\\.\\*\\)\\+.*\\//, message: 'Catastrophic backtracking: (.*)+ pattern' },\r\n    { pattern: /\\/.*\\(\\.\\+\\)\\*.*\\//, message: 'Catastrophic backtracking: (.+)* pattern' },\r\n    { pattern: /\\/.*\\(\\.\\*\\)\\*.*\\//, message: 'Catastrophic backtracking: (.*)*  pattern' },\r\n    { pattern: /\\/.*\\(\\.\\+\\)\\+.*\\//, message: 'Catastrophic backtracking: (.+)+ pattern' },\r\n    { pattern: /\\/.*\\(\\.\\*\\)\\{.*,.*\\}.*\\//, message: 'Potentially expensive: (.*)* with large quantifier' }\r\n  ];\r\n  \r\n  lines.forEach((line, index) => {\r\n    dangerousPatterns.forEach(({ pattern, message }) => {\r\n      if (pattern.test(line)) {\r\n        issues.push({\r\n          type: 'performance',\r\n          message: message + ' - may cause exponential time complexity',\r\n          line: index + 1,\r\n          severity: 'high',\r\n          code: line.trim(),\r\n          pattern: 'inefficient_regex'\r\n        });\r\n      }\r\n    });\r\n    \r\n    // Very long regex patterns\r\n    var regexMatch = line.match(/\\/(.{50,})\\//);\r\n    if (regexMatch) {\r\n      issues.push({\r\n        type: 'performance',\r\n        message: 'Complex regex pattern: Consider breaking into smaller patterns',\r\n        line: index + 1,\r\n        severity: 'medium',\r\n        code: line.trim(),\r\n        pattern: 'complex_regex'\r\n      });\r\n    }\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// 14. MEMORY LEAKS DETECTION\r\nfunction checkMemoryLeaks(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  lines.forEach((line, index) => {\r\n    // Timers without cleanup\r\n    if (/setInterval|setTimeout/i.test(line) && !/clearInterval|clearTimeout/i.test(content)) {\r\n      issues.push({\r\n        type: 'performance',\r\n        message: 'Memory leak: Timer created but never cleared',\r\n        line: index + 1,\r\n        severity: 'medium',\r\n        code: line.trim(),\r\n        pattern: 'timer_leak'\r\n      });\r\n    }\r\n    \r\n    // Event listeners in loops\r\n    if (/for\\s*\\(|while\\s*\\(|\\.forEach/i.test(line)) {\r\n      var nextLines = lines.slice(index, index + 10).join('\\n');\r\n      if (/addEventListener|on\\s*\\(/i.test(nextLines)) {\r\n        issues.push({\r\n          type: 'performance',\r\n          message: 'Memory leak: Event listeners created in loop without cleanup',\r\n          line: index + 1,\r\n          severity: 'high',\r\n          code: line.trim(),\r\n          pattern: 'loop_event_leak'\r\n        });\r\n      }\r\n    }\r\n    \r\n    // Global arrays that only grow\r\n    if (/\\.push\\s*\\(|\\.unshift\\s*\\(/i.test(line) && /global|window|process/i.test(line)) {\r\n      if (!/\\.pop|\\.shift|\\.splice|\\.length\\s*=\\s*0|clear/i.test(content)) {\r\n        issues.push({\r\n          type: 'performance',\r\n          message: 'Memory leak: Global array grows but never shrinks',\r\n          line: index + 1,\r\n          severity: 'medium',\r\n          code: line.trim(),\r\n          pattern: 'growing_global_array'\r\n        });\r\n      }\r\n    }\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// 15. PERFORMANCE ANTIPATTERNS\r\nfunction checkPerformanceAntipatterns(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  lines.forEach((line, index) => {\r\n    // String concatenation in loops\r\n    if (/for\\s*\\(|while\\s*\\(|\\.forEach/i.test(line)) {\r\n      var nextLines = lines.slice(index, index + 10).join('\\n');\r\n      if (/\\+\\s*=.*[\"']|concat\\s*\\(/i.test(nextLines)) {\r\n        issues.push({\r\n          type: 'performance',\r\n          message: 'Performance issue: String concatenation in loop - use array.join() or StringBuilder',\r\n          line: index + 1,\r\n          severity: 'medium',\r\n          code: line.trim(),\r\n          pattern: 'string_concat_loop'\r\n        });\r\n      }\r\n    }\r\n    \r\n    // REMOVED: Inefficient array operations (low severity noise)\r\n    // if (/\\.indexOf\\s*\\(.*\\)\\s*!==\\s*-1/i.test(line)) {\r\n    //   issues.push({\r\n    //     type: 'performance',\r\n    //     message: 'Performance: Use .includes() instead of .indexOf() !== -1',\r\n    //     line: index + 1,\r\n    //     severity: 'low',\r\n    //     code: line.trim(),\r\n    //     pattern: 'inefficient_array_check'\r\n    //   });\r\n    // }\r\n    \r\n    // Synchronous file operations in async context\r\n    if (/readFileSync|writeFileSync|existsSync/i.test(line)) {\r\n      var surroundingCode = lines.slice(Math.max(0, index - 5), index + 5).join('\\n');\r\n      if (/async|await|Promise/i.test(surroundingCode)) {\r\n        issues.push({\r\n          type: 'performance',\r\n          message: 'Performance: Use async file operations instead of sync in async context',\r\n          line: index + 1,\r\n          severity: 'medium',\r\n          code: line.trim(),\r\n          pattern: 'sync_in_async'\r\n        });\r\n      }\r\n    }\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// ðŸ” CODE QUALITY CHECKS\r\n\r\n// 16. COMPLEXITY ANALYSIS\r\nfunction checkComplexity(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  var currentFunction = null;\r\n  var complexity = 0;\r\n  var functionStart = 0;\r\n  var braceDepth = 0;\r\n  \r\n  lines.forEach((line, index) => {\r\n    // Track brace depth\r\n    braceDepth += (line.match(/\\{/g) || []).length;\r\n    braceDepth -= (line.match(/\\}/g) || []).length;\r\n    \r\n    // Function start\r\n    var funcMatch = line.match(/function\\s+(\\w+)|const\\s+(\\w+)\\s*=.*=>|def\\s+(\\w+)|(\\w+)\\s*\\(/i);\r\n    if (funcMatch && /function|const.*=>|def\\s+/i.test(line)) {\r\n      if (currentFunction && complexity > 10) {\r\n        issues.push({\r\n          type: 'maintainability',\r\n          message: `High cyclomatic complexity (${complexity}): Break function into smaller pieces`,\r\n          line: functionStart,\r\n          severity: 'medium',\r\n          code: `function ${currentFunction}...`,\r\n          pattern: 'high_complexity'\r\n        });\r\n      }\r\n      \r\n      currentFunction = funcMatch[1] || funcMatch[2] || funcMatch[3] || funcMatch[4];\r\n      complexity = 1;\r\n      functionStart = index + 1;\r\n    }\r\n    \r\n    // Complexity indicators\r\n    if (/if\\s*\\(|else|elif|while\\s*\\(|for\\s*\\(|catch|case\\s+|switch\\s*\\(/i.test(line)) {\r\n      complexity++;\r\n    }\r\n    if (/&&|\\|\\||and\\s+|or\\s+/i.test(line)) {\r\n      complexity += (line.match(/&&|\\|\\|/g) || []).length;\r\n    }\r\n    \r\n    // REMOVED: Long function check (low severity noise)  \r\n    // if (currentFunction && braceDepth === 0 && index - functionStart > 50) {\r\n    //   issues.push({\r\n    //     type: 'maintainability',\r\n    //     message: `Long function (${index - functionStart + 1} lines): Consider breaking into smaller functions`,\r\n    //     line: functionStart,\r\n    //     severity: 'low',\r\n    //     code: `function ${currentFunction}...`,\r\n    //     pattern: 'long_function'\r\n    //   });\r\n    // }\r\n  });\r\n  \r\n  // Check last function\r\n  if (currentFunction && complexity > 10) {\r\n    issues.push({\r\n      type: 'maintainability',\r\n      message: `High cyclomatic complexity (${complexity}): Break function into smaller pieces`,\r\n      line: functionStart,\r\n      severity: 'medium',\r\n      code: `function ${currentFunction}...`,\r\n      pattern: 'high_complexity'\r\n    });\r\n  }\r\n  \r\n  return issues;\r\n}\r\n\r\n// 17. CODE SMELLS DETECTION\r\nfunction checkCodeSmells(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  lines.forEach((line, index) => {\r\n    // REMOVED: Magic numbers, TODO comments, commented code\r\n    // These are \"informational\" issues that create noise\r\n    // Focus only on medium+ severity issues that matter\r\n    \r\n    // Long parameter lists\r\n    var paramMatch = line.match(/function.*\\(([^)]+)\\)|.*\\(([^)]+)\\)\\s*=>/);\r\n    if (paramMatch) {\r\n      var params = (paramMatch[1] || paramMatch[2]).split(',');\r\n      if (params.length > 5) {\r\n        issues.push({\r\n          type: 'maintainability',\r\n          message: `Too many parameters (${params.length}): Consider using an options object`,\r\n          line: index + 1,\r\n          severity: 'medium',\r\n          code: line.trim(),\r\n          pattern: 'long_parameter_list'\r\n        });\r\n      }\r\n    }\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// 18. BEST PRACTICES CHECK\r\nfunction checkBestPractices(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  lines.forEach((line, index) => {\r\n    // == instead of ===  (Keep only medium+ severity issues)\r\n    if (/[^=!]==[^=]|[^=!]!=[^=]/.test(line)) {\r\n      issues.push({\r\n        type: 'logic',\r\n        message: 'Use === or !== for strict equality comparison',\r\n        line: index + 1,\r\n        severity: 'medium',\r\n        code: line.trim(),\r\n        pattern: 'loose_equality'\r\n      });\r\n    }\r\n    \r\n    // REMOVED: console.log, var usage, missing semicolons\r\n    // These are \"informational\" noise that inflates issue counts\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// ðŸ”— CROSS-FILE ANALYSIS\r\n\r\n// 19. UNUSED IMPORTS DETECTION\r\nfunction checkUnusedImports(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  var imports = [];\r\n  \r\n  lines.forEach((line, index) => {\r\n    // ES6 imports\r\n    var esImportMatch = line.match(/import\\s+(?:\\{([^}]+)\\}|\\*\\s+as\\s+(\\w+)|(\\w+))\\s+from/i);\r\n    if (esImportMatch) {\r\n      var importedItems = [];\r\n      if (esImportMatch[1]) { // Named imports\r\n        importedItems = esImportMatch[1].split(',').map(s => s.trim().replace(/\\s+as\\s+\\w+/, ''));\r\n      } else if (esImportMatch[2]) { // Namespace import\r\n        importedItems = [esImportMatch[2]];\r\n      } else if (esImportMatch[3]) { // Default import\r\n        importedItems = [esImportMatch[3]];\r\n      }\r\n      \r\n      importedItems.forEach(item => {\r\n        imports.push({\r\n          name: item,\r\n          line: index + 1,\r\n          code: line.trim()\r\n        });\r\n      });\r\n    }\r\n    \r\n    // CommonJS require\r\n    var requireMatch = line.match(/(?:const|let|var)\\s+(?:\\{([^}]+)\\}|(\\w+))\\s*=\\s*require/i);\r\n    if (requireMatch) {\r\n      var requiredItems = [];\r\n      if (requireMatch[1]) { // Destructured require\r\n        requiredItems = requireMatch[1].split(',').map(s => s.trim());\r\n      } else if (requireMatch[2]) { // Direct require\r\n        requiredItems = [requireMatch[2]];\r\n      }\r\n      \r\n      requiredItems.forEach(item => {\r\n        imports.push({\r\n          name: item,\r\n          line: index + 1,\r\n          code: line.trim()\r\n        });\r\n      });\r\n    }\r\n  });\r\n  \r\n  // Check if imports are used\r\n  imports.forEach(imp => {\r\n    var isUsed = content.split('\\n').some((line, idx) => \r\n      idx !== imp.line - 1 && \r\n      new RegExp('\\\\b' + imp.name.replace(/[.*+?^${}()|[\\]\\\\]/g, '\\\\$&') + '\\\\b').test(line)\r\n    );\r\n    \r\n    // REMOVED: Unused imports detection\r\n    // This is informational noise - bundlers tree-shake unused imports\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// 20. IMPORT ISSUES DETECTION\r\nfunction checkImportIssues(content, filePath, repoDir) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  lines.forEach((line, index) => {\r\n    // Relative imports that might be problematic\r\n    if (/import.*from\\s*[\"']\\.\\.?\\//i.test(line)) {\r\n      var importPath = line.match(/from\\s*[\"']([^\"']+)[\"']/i);\r\n      if (importPath && importPath[1]) {\r\n        var relativePath = importPath[1];\r\n        \r\n        // REMOVED: Deep relative imports (low severity noise)\r\n        // if ((relativePath.match(/\\.\\.\\//g) || []).length > 2) {\r\n        //   issues.push({\r\n        //     type: 'maintainability',\r\n        //     message: 'Deep relative import: Consider restructuring or using absolute imports',\r\n        //     line: index + 1,\r\n        //     severity: 'low',\r\n        //     code: line.trim(),\r\n        //     pattern: 'deep_relative_import'\r\n        //   });\r\n        // }\r\n        \r\n        // REMOVED: Parent directory import warnings\r\n        // This is informational noise - relative imports are normal\r\n      }\r\n    }\r\n    \r\n    // REMOVED: Missing file extensions \r\n    // This is informational noise - modern bundlers handle this\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// ðŸ”’ SECURITY VULNERABILITY DETECTION\r\nfunction detectSecurityVulnerabilities(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  lines.forEach((line, index) => {\r\n    var lineNum = index + 1;\r\n    \r\n    // SQL Injection Detection\r\n    if (/\\$\\{.*\\}.*query|query.*\\$\\{|\\+.*query|query.*\\+/i.test(line) && /sql|select|insert|update|delete/i.test(line)) {\r\n      issues.push({\r\n        type: 'security',\r\n        message: 'Potential SQL injection: Query uses string concatenation instead of parameterized queries',\r\n        line: lineNum,\r\n        severity: 'critical',\r\n        code: line.trim(),\r\n        pattern: 'sql_injection'\r\n      });\r\n    }\r\n    \r\n    // XSS Detection\r\n    if (/innerHTML|outerHTML|document\\.write/i.test(line) && !/sanitize|escape|encode/i.test(line)) {\r\n      issues.push({\r\n        type: 'security', \r\n        message: 'Potential XSS: Dynamic HTML insertion without sanitization',\r\n        line: lineNum,\r\n        severity: 'high',\r\n        code: line.trim(),\r\n        pattern: 'xss_vulnerability'\r\n      });\r\n    }\r\n    \r\n    // Command Injection Detection\r\n    if (/exec|spawn|system/i.test(line) && /\\$\\{|\\+|concat/i.test(line)) {\r\n      issues.push({\r\n        type: 'security',\r\n        message: 'Potential command injection: System command uses unsanitized input',\r\n        line: lineNum,\r\n        severity: 'critical', \r\n        code: line.trim(),\r\n        pattern: 'command_injection'\r\n      });\r\n    }\r\n    \r\n    // Hardcoded Secrets Detection\r\n    if (/(password|secret|key|token)\\s*[:=]\\s*[\"'][^\"']{8,}/i.test(line)) {\r\n      issues.push({\r\n        type: 'security',\r\n        message: 'Hardcoded secret detected: Sensitive data should be in environment variables',\r\n        line: lineNum,\r\n        severity: 'high',\r\n        code: line.replace(/[\"'][^\"']*[\"']/, '\"***REDACTED***\"'),\r\n        pattern: 'hardcoded_secret'\r\n      });\r\n    }\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// ðŸ› LOGIC BUG DETECTION  \r\nfunction detectLogicBugs(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  lines.forEach((line, index) => {\r\n    var lineNum = index + 1;\r\n    \r\n    // Silent Exception Swallowing\r\n    if (/catch.*\\{[\\s]*\\}|catch.*\\{\\s*\\/\\/|catch.*\\{\\s*console\\.log/i.test(line)) {\r\n      issues.push({\r\n        type: 'logic',\r\n        message: 'Silent exception handling: Errors are caught but not properly handled',\r\n        line: lineNum,\r\n        severity: 'high',\r\n        code: line.trim(),\r\n        pattern: 'silent_exception'\r\n      });\r\n    }\r\n    \r\n    // Async Without Error Handling\r\n    if (/await\\s+\\w+\\(/i.test(line) && !/try|catch/i.test(content.slice(content.indexOf(line) - 200, content.indexOf(line) + 200))) {\r\n      issues.push({\r\n        type: 'logic',\r\n        message: 'Unhandled async operation: await call without try-catch block',\r\n        line: lineNum,\r\n        severity: 'medium',\r\n        code: line.trim(),\r\n        pattern: 'unhandled_async'\r\n      });\r\n    }\r\n    \r\n    // Null/Undefined Dereference\r\n    if (/\\.length|\\.push|\\.map|\\.filter/i.test(line) && !/if.*null|if.*undefined|\\?\\./i.test(line)) {\r\n      var prevLine = lines[index - 1] || '';\r\n      if (!/if.*null|if.*undefined/i.test(prevLine)) {\r\n        issues.push({\r\n          type: 'logic',\r\n          message: 'Potential null dereference: Object method called without null check',\r\n          line: lineNum,\r\n          severity: 'medium',\r\n          code: line.trim(),\r\n          pattern: 'null_dereference'\r\n        });\r\n      }\r\n    }\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// âš¡ PERFORMANCE BUG DETECTION\r\nfunction detectPerformanceBugs(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  lines.forEach((line, index) => {\r\n    var lineNum = index + 1;\r\n    \r\n    // Database Query in Loop\r\n    if (/for\\s*\\(|while\\s*\\(|\\.forEach|\\.map/i.test(line)) {\r\n      var nextFewLines = lines.slice(index, index + 10).join('\\n');\r\n      if (/query|findOne|findMany|select|insert|update/i.test(nextFewLines)) {\r\n        issues.push({\r\n          type: 'performance',\r\n          message: 'N+1 Query Problem: Database query inside loop - consider batch operations',\r\n          line: lineNum,\r\n          severity: 'high',\r\n          code: line.trim(),\r\n          pattern: 'n_plus_one_query'\r\n        });\r\n      }\r\n    }\r\n    \r\n    // Inefficient Regex\r\n    if (/new RegExp|\\/.*\\*.*\\/|\\/.*\\+.*\\+/i.test(line)) {\r\n      issues.push({\r\n        type: 'performance',\r\n        message: 'Potentially inefficient regex: Complex pattern may cause performance issues',\r\n        line: lineNum,\r\n        severity: 'medium',\r\n        code: line.trim(),\r\n        pattern: 'inefficient_regex'\r\n      });\r\n    }\r\n    \r\n    // Memory Leak Patterns\r\n    if (/addEventListener|setInterval|setTimeout/i.test(line) && !/removeEventListener|clearInterval|clearTimeout/i.test(content)) {\r\n      issues.push({\r\n        type: 'performance',\r\n        message: 'Potential memory leak: Event listener/timer added but never removed',\r\n        line: lineNum,\r\n        severity: 'medium',\r\n        code: line.trim(),\r\n        pattern: 'memory_leak'\r\n      });\r\n    }\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// ðŸ”— CROSS-FILE RELATIONSHIP ANALYSIS (simplified for now)\r\nasync function detectCrossFileIssues(content, filePath, repoDir) {\r\n  var issues = [];\r\n  \r\n  // This is where we'd do semantic indexing and cross-file analysis\r\n  // For now, just detect obvious import/export mismatches\r\n  var lines = content.split('\\n');\r\n  \r\n  lines.forEach((line, index) => {\r\n    var lineNum = index + 1;\r\n    \r\n    // Import/Export Mismatch Detection (simplified)\r\n    if (/import.*from\\s*[\"']\\.\\.?\\//i.test(line)) {\r\n      var importPath = line.match(/from\\s*[\"']([^\"']+)[\"']/i);\r\n      if (importPath && !importPath[1].includes('node_modules')) {\r\n        // TODO: Check if imported file exists and exports match\r\n        // For now, just flag relative imports for review\r\n        // REMOVED: Relative import detection (low severity noise)\r\n        // issues.push({\r\n        //   type: 'logic',\r\n        //   message: 'Relative import detected - verify file exists and exports match',\r\n        //   line: lineNum,\r\n        //   severity: 'low',\r\n        //   code: line.trim(),\r\n        //   pattern: 'import_mismatch'\r\n        // });\r\n      }\r\n    }\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// ðŸ§  SMART AI ANALYSIS: Efficient and context-aware  \r\nasync function performAIAnalysis(content, filePath) {\r\n  console.log(`ðŸ§  Running AI analysis for: ${filePath}`);\r\n  \r\n  if (!OPENAI_API_KEY) {\r\n    console.warn('âš ï¸ OpenAI API key missing, using fallback analysis');\r\n    return performBasicAnalysis(content, filePath);\r\n  }\r\n  \r\n  try {\r\n    // Smart filtering: Only analyze files with potential issues\r\n    var hasSecurityKeywords = /password|token|secret|eval|innerHTML|sql|query|auth|dangerous/i.test(content);\r\n    var hasPerformanceKeywords = /useEffect|useState|for.*in|while|setTimeout|setInterval/i.test(content);\r\n    var hasErrorKeywords = /try|catch|throw|error|exception|null|undefined/i.test(content);\r\n    var isComplexFile = content.length > 1000;\r\n    \r\n    // Skip only very simple files (but still analyze most files)\r\n    if (!hasSecurityKeywords && !hasPerformanceKeywords && !hasErrorKeywords && content.length < 300) {\r\n      console.log(`â­ï¸ Skipping very simple file: ${filePath} (< 300 chars, no risk patterns)`);\r\n      return [];\r\n    }\r\n    \r\n    // Truncate very large files to save tokens (keep most important parts)\r\n    var analysisContent = content;\r\n    if (content.length > 3000) {\r\n      var lines = content.split('\\n');\r\n      var importSection = lines.slice(0, 20).join('\\n');  // Keep imports\r\n      var mainSection = lines.slice(20, -20).join('\\n').substring(0, 2000); // Middle part\r\n      var endSection = lines.slice(-20).join('\\n');  // Keep end\r\n      analysisContent = importSection + '\\n// ... (middle truncated) ...\\n' + mainSection + '\\n// ... (end part) ...\\n' + endSection;\r\n    }\r\n    \r\n    var ext = path.extname(filePath).toLowerCase();\r\n    var language = ext === '.py' ? 'Python' : ext === '.js' || ext === '.jsx' ? 'JavaScript' : \r\n                   ext === '.ts' || ext === '.tsx' ? 'TypeScript' : ext === '.cpp' || ext === '.cc' ? 'C++' : \r\n                   ext === '.c' ? 'C' : ext === '.java' ? 'Java' : 'code';\r\n    \r\n    var prompt = `You are an expert ${language} security and performance analyst. Analyze this code for CRITICAL issues only.\r\n\r\nFOCUS ON:\r\n1. ðŸ”’ Security: XSS, injection, secrets, unsafe operations\r\n2. âš¡ Performance: infinite loops, memory leaks, inefficient algorithms  \r\n3. ðŸ› Logic: null pointers, race conditions, error handling\r\n\r\nFile: ${filePath}\r\n\\`\\`\\`${language.toLowerCase()}\r\n${analysisContent}\r\n\\`\\`\\`\r\n\r\nReturn ONLY a JSON array of real issues. Be precise with line numbers:\r\n[{\"type\": \"security|performance|logic\", \"message\": \"specific issue description\", \"line\": actual_line_number, \"severity\": \"critical|high|medium\", \"code\": \"exact problematic line\"}]\r\n\r\nRules:\r\n- Only return ACTUAL problems, not style/formatting\r\n- Line numbers must be accurate\r\n- Be specific in messages (not generic)\r\n- Return [] if no critical issues found\r\n- Max 10 issues per file`;\r\n\r\n    var response = await fetch('https://api.openai.com/v1/chat/completions', {\r\n      method: 'POST',\r\n      headers: {\r\n        'Authorization': `Bearer ${OPENAI_API_KEY}`,\r\n        'Content-Type': 'application/json'\r\n      },\r\n      body: JSON.stringify({\r\n        model: 'gpt-4o-mini',  // Fast and cost-effective\r\n        messages: [{ role: 'user', content: prompt }],\r\n        max_tokens: 800,  // Reasonable response size\r\n        temperature: 0.1  // Consistent results\r\n      })\r\n    });\r\n    \r\n    if (!response.ok) {\r\n      console.error(`âŒ OpenAI API error: ${response.status}`);\r\n      return performBasicAnalysis(content, filePath);\r\n    }\r\n    \r\n    var data = await response.json();\r\n    var aiResponse = data.choices[0].message.content.trim();\r\n    \r\n    // Extract JSON from response\r\n    var jsonMatch = aiResponse.match(/\\[[\\s\\S]*?\\]/);\r\n    if (jsonMatch) {\r\n      try {\r\n        var issues = JSON.parse(jsonMatch[0]);\r\n        console.log(`ðŸ§  AI found ${issues.length} issues in ${filePath}`);\r\n        return Array.isArray(issues) ? issues : [];\r\n      } catch (parseError) {\r\n        console.warn(`âš ï¸ Failed to parse AI JSON for ${filePath}:`, parseError.message);\r\n        return [];\r\n      }\r\n    } else {\r\n      console.log(`â„¹ï¸ AI found no JSON issues in ${filePath}`);\r\n      // Fallback to basic analysis if AI doesn't find structured issues\r\n      console.log(`ðŸ”„ Running fallback pattern analysis for ${filePath}`);\r\n      return performBasicAnalysis(content, filePath);\r\n    }\r\n    \r\n  } catch (error) {\r\n    console.error(`âŒ AI analysis failed for ${filePath}:`, error.message);\r\n    return performBasicAnalysis(content, filePath);\r\n  }\r\n}\r\n\r\n// ðŸš€ ULTIMATE FILE-SPECIFIC ANALYSIS ENGINE\r\nasync function performHybridAnalysis(content, filePath, tempDir) {\r\n  console.log(`ðŸŽ¯ SMART FILE ANALYSIS: ${filePath}`);\r\n  \r\n  var startTime = Date.now();\r\n  var ext = path.extname(filePath).toLowerCase();\r\n  var fileName = path.basename(filePath).toLowerCase();\r\n  \r\n  try {\r\n    // PHASE 1: ðŸ” INTELLIGENT FILE CLASSIFICATION & SPECIALIZED ANALYSIS\r\n    var fileType = classifyFileType(filePath, content);\r\n    console.log(`ðŸ“‹ File classified as: ${fileType.category} (${fileType.subtype})`);\r\n    \r\n    var issues = [];\r\n    \r\n    // PHASE 2: âš¡ SPECIALIZED ANALYZERS (Ultra-fast, file-specific)\r\n    switch (fileType.category) {\r\n      case 'code':\r\n        issues = await analyzeCodeFile(content, filePath, fileType, tempDir);\r\n        break;\r\n      case 'config':\r\n        issues = analyzeConfigFile(content, filePath, fileType);\r\n        break;\r\n      case 'security':\r\n        issues = analyzeSecurityFile(content, filePath, fileType);\r\n        break;\r\n      case 'build':\r\n        issues = analyzeBuildFile(content, filePath, fileType);\r\n        break;\r\n      case 'docs':\r\n        issues = analyzeDocumentationFile(content, filePath, fileType);\r\n        break;\r\n      case 'data':\r\n        issues = analyzeDataFile(content, filePath, fileType);\r\n        break;\r\n      default:\r\n        issues = performBasicAnalysis(content, filePath);\r\n    }\r\n    \r\n    // PHASE 3: ðŸŽ¯ PRIORITY SCORING & ENHANCEMENT\r\n    issues = enhanceIssuesWithMetadata(issues, fileType, content, filePath);\r\n    \r\n    var analysisTime = Date.now() - startTime;\r\n    console.log(`ðŸŽ¯ SPECIALIZED ANALYSIS COMPLETE: ${issues.length} issues in ${analysisTime}ms`);\r\n    \r\n    return issues;\r\n    \r\n  } catch (error) {\r\n    console.error(`âŒ Specialized analysis failed for ${filePath}:`, error.message);\r\n    return performBasicAnalysis(content, filePath);\r\n  }\r\n}\r\n\r\n// ðŸŽ¯ INTELLIGENT AI DECISION ENGINE\r\nfunction decideShouldUseAI(content, filePath, staticIssues) {\r\n  var ext = path.extname(filePath).toLowerCase();\r\n  \r\n  // Always use AI for complex files\r\n  if (content.length > 2000) return true;\r\n  \r\n  // Use AI if static analysis found critical issues (for better explanations)\r\n  if (staticIssues && staticIssues.some(issue => issue.severity === 'critical')) return true;\r\n  \r\n  // Use AI for security-sensitive files\r\n  if (/password|token|secret|auth|crypto|security/i.test(content)) return true;\r\n  \r\n  // Use AI for complex React components\r\n  if (['.jsx', '.tsx'].includes(ext) && /useEffect|useState|useContext/i.test(content)) return true;\r\n  \r\n  // Use AI for C/C++ with pointers (memory safety)\r\n  if (['.c', '.cpp', '.cc'].includes(ext) && /\\*|malloc|free|delete/i.test(content)) return true;\r\n  \r\n  // Use AI for Python with ML/AI libraries\r\n  if (ext === '.py' && /tensorflow|pytorch|numpy|pandas/i.test(content)) return true;\r\n  \r\n  // Skip AI for simple files\r\n  return false;\r\n}\r\n\r\n// ðŸ”„ SMART DEDUPLICATION ENGINE  \r\nfunction deduplicateIssues(staticIssues, aiIssues) {\r\n  if (!staticIssues || staticIssues.length === 0) return aiIssues;\r\n  if (!aiIssues || aiIssues.length === 0) return [];\r\n  \r\n  var uniqueAIIssues = [];\r\n  \r\n  aiIssues.forEach(function(aiIssue) {\r\n    var isDuplicate = staticIssues.some(function(staticIssue) {\r\n      // Same line number and similar message\r\n      return Math.abs(aiIssue.line - staticIssue.line) <= 2 && \r\n             (aiIssue.message.toLowerCase().includes(staticIssue.message.toLowerCase().substring(0, 20)) ||\r\n              staticIssue.message.toLowerCase().includes(aiIssue.message.toLowerCase().substring(0, 20)));\r\n    });\r\n    \r\n    if (!isDuplicate) {\r\n      uniqueAIIssues.push(aiIssue);\r\n    }\r\n  });\r\n  \r\n  return uniqueAIIssues;\r\n}\r\n\r\n// ðŸ† INTELLIGENT PRIORITY SCORING\r\nfunction prioritizeIssues(issues, content, filePath) {\r\n  issues.forEach(function(issue) {\r\n    var score = 0;\r\n    \r\n    // Base severity score\r\n    if (issue.severity === 'critical') score += 100;\r\n    else if (issue.severity === 'high') score += 75;\r\n    else if (issue.severity === 'medium') score += 50;\r\n    else score += 25;\r\n    \r\n    // Source confidence boost\r\n    if (issue.source === 'static') score += 20; // Static analysis is reliable\r\n    if (issue.source === 'ai') score += 10;     // AI provides context\r\n    \r\n    // Security issues get priority\r\n    if (issue.type === 'security') score += 30;\r\n    \r\n    // Performance issues in hot paths\r\n    if (issue.type === 'performance' && /loop|render|effect/i.test(issue.message)) score += 15;\r\n    \r\n    // Critical files get attention\r\n    if (/index|main|app|server|auth|security/i.test(filePath)) score += 10;\r\n    \r\n    issue.priorityScore = score;\r\n  });\r\n  \r\n  // Sort by priority score (highest first)\r\n  return issues.sort(function(a, b) { return b.priorityScore - a.priorityScore; });\r\n}\r\n\r\n// ðŸ§  INTELLIGENT FILE CLASSIFIER\r\nfunction classifyFileType(filePath, content) {\r\n  var ext = path.extname(filePath).toLowerCase();\r\n  var fileName = path.basename(filePath).toLowerCase();\r\n  var dirPath = path.dirname(filePath).toLowerCase();\r\n  \r\n  // CODE FILES - Need deep analysis\r\n  if (['.js', '.jsx', '.ts', '.tsx', '.py', '.java', '.cpp', '.c', '.h', '.go', '.rs', '.php', '.rb'].includes(ext)) {\r\n    var subtype = 'general';\r\n    if (/react|component|hook/i.test(content) || ['.jsx', '.tsx'].includes(ext)) subtype = 'react';\r\n    else if (/express|server|api|route/i.test(content)) subtype = 'backend';\r\n    else if (/test|spec|__test__/i.test(fileName)) subtype = 'test';\r\n    else if (/tensorflow|pytorch|numpy|ml|ai/i.test(content)) subtype = 'ml';\r\n    return { category: 'code', subtype: subtype, priority: 'high' };\r\n  }\r\n  \r\n  // SECURITY FILES - Critical analysis\r\n  if (fileName.includes('auth') || fileName.includes('security') || fileName.includes('secret') || \r\n      fileName.includes('key') || fileName.includes('cert') || ext === '.pem' || ext === '.key') {\r\n    return { category: 'security', subtype: 'credentials', priority: 'critical' };\r\n  }\r\n  \r\n  // CONFIG FILES - Structured analysis\r\n  if (['.json', '.yaml', '.yml', '.toml', '.ini', '.conf', '.cfg'].includes(ext) ||\r\n      ['package.json', 'tsconfig.json', 'webpack.config.js', '.env', '.gitignore'].includes(fileName)) {\r\n    var subtype = 'general';\r\n    if (fileName === 'package.json') subtype = 'npm';\r\n    else if (fileName.includes('docker')) subtype = 'docker';\r\n    else if (fileName.includes('webpack') || fileName.includes('babel')) subtype = 'build';\r\n    else if (fileName === '.env' || fileName.includes('env')) subtype = 'environment';\r\n    return { category: 'config', subtype: subtype, priority: 'medium' };\r\n  }\r\n  \r\n  // BUILD FILES - Deployment analysis  \r\n  if (['dockerfile', 'makefile', 'gulpfile.js', 'gruntfile.js'].includes(fileName) ||\r\n      fileName.includes('build') || fileName.includes('deploy') || ext === '.sh' || ext === '.bat') {\r\n    return { category: 'build', subtype: 'deployment', priority: 'high' };\r\n  }\r\n  \r\n  // DATA FILES - Format validation\r\n  if (['.csv', '.xml', '.sql', '.db', '.sqlite'].includes(ext)) {\r\n    return { category: 'data', subtype: 'structured', priority: 'low' };\r\n  }\r\n  \r\n  // DOCUMENTATION - Content analysis\r\n  if (['.md', '.txt', '.rst', '.adoc'].includes(ext) || fileName === 'readme') {\r\n    return { category: 'docs', subtype: 'markdown', priority: 'low' };\r\n  }\r\n  \r\n  return { category: 'unknown', subtype: 'generic', priority: 'low' };\r\n}\r\n\r\n// ðŸ’» CODE FILE ANALYZER (AI-Enhanced for Complex Logic)\r\nasync function analyzeCodeFile(content, filePath, fileType, tempDir) {\r\n  console.log(`ðŸ’» Analyzing ${fileType.subtype} code file: ${filePath}`);\r\n  \r\n  var issues = [];\r\n  \r\n  // PHASE 1: Fast pattern-based analysis\r\n  var patterns = getCodePatterns(fileType.subtype);\r\n  issues = issues.concat(analyzeWithPatterns(content, patterns, filePath));\r\n  \r\n  // PHASE 2: AI analysis for complex files only\r\n  if (content.length > 1000 || issues.some(i => i.severity === 'critical')) {\r\n    console.log(`ðŸ§  Using AI for complex ${fileType.subtype} analysis`);\r\n    var aiIssues = await performAIAnalysis(content, filePath);\r\n    if (aiIssues) {\r\n      aiIssues.forEach(issue => issue.source = 'ai');\r\n      issues = issues.concat(aiIssues);\r\n    }\r\n  }\r\n  \r\n  return issues;\r\n}\r\n\r\n// âš™ï¸ CONFIG FILE ANALYZER (100+ Predefined Rules)\r\nfunction analyzeConfigFile(content, filePath, fileType) {\r\n  console.log(`âš™ï¸ Analyzing ${fileType.subtype} config: ${filePath}`);\r\n  \r\n  var issues = [];\r\n  var fileName = path.basename(filePath);\r\n  \r\n  try {\r\n    if (fileType.subtype === 'npm' && fileName === 'package.json') {\r\n      issues = issues.concat(analyzePackageJson(content, filePath));\r\n    } else if (fileType.subtype === 'environment') {\r\n      issues = issues.concat(analyzeEnvFile(content, filePath));\r\n    } else if (fileType.subtype === 'docker') {\r\n      issues = issues.concat(analyzeDockerfile(content, filePath));\r\n    } else if (['.json', '.yaml', '.yml'].includes(path.extname(filePath))) {\r\n      issues = issues.concat(analyzeGenericConfig(content, filePath));\r\n    }\r\n  } catch (error) {\r\n    console.warn(`Config analysis failed for ${filePath}:`, error.message);\r\n  }\r\n  \r\n  return issues;\r\n}\r\n\r\n// ðŸ”’ SECURITY FILE ANALYZER (Critical Security Checks)\r\nfunction analyzeSecurityFile(content, filePath, fileType) {\r\n  console.log(`ðŸ”’ Security analysis: ${filePath}`);\r\n  \r\n  var issues = [];\r\n  \r\n  // Check for exposed secrets\r\n  var secretPatterns = [\r\n    { pattern: /sk-[a-zA-Z0-9]{48}/, message: 'OpenAI API key exposed', severity: 'critical' },\r\n    { pattern: /ghp_[a-zA-Z0-9]{36}/, message: 'GitHub token exposed', severity: 'critical' },\r\n    { pattern: /AKIA[0-9A-Z]{16}/, message: 'AWS access key exposed', severity: 'critical' },\r\n    { pattern: /-----BEGIN PRIVATE KEY-----/, message: 'Private key exposed', severity: 'critical' },\r\n    { pattern: /password\\s*[=:]\\s*[\"'][^\"']{8,}[\"']/, message: 'Hardcoded password', severity: 'high' }\r\n  ];\r\n  \r\n  secretPatterns.forEach(function(check) {\r\n    if (check.pattern.test(content)) {\r\n      issues.push({\r\n        type: 'security',\r\n        message: check.message,\r\n        line: findLineNumber(content, check.pattern),\r\n        severity: check.severity,\r\n        source: 'security-scanner'\r\n      });\r\n    }\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// ðŸ—ï¸ BUILD FILE ANALYZER (Deployment & CI/CD Issues)\r\nfunction analyzeBuildFile(content, filePath, fileType) {\r\n  console.log(`ðŸ—ï¸ Build file analysis: ${filePath}`);\r\n  \r\n  var issues = [];\r\n  var fileName = path.basename(filePath).toLowerCase();\r\n  \r\n  if (fileName === 'dockerfile') {\r\n    issues = issues.concat(analyzeDockerfile(content, filePath));\r\n  } else if (path.extname(filePath) === '.sh') {\r\n    issues = issues.concat(analyzeShellScript(content, filePath));\r\n  }\r\n  \r\n  return issues;\r\n}\r\n\r\n// ðŸ“š DOCUMENTATION ANALYZER (Content Quality)\r\nfunction analyzeDocumentationFile(content, filePath, fileType) {\r\n  console.log(`ðŸ“š Documentation analysis: ${filePath}`);\r\n  \r\n  var issues = [];\r\n  \r\n  // Check for common documentation issues\r\n  if (content.length < 100) {\r\n    // REMOVED: Short documentation file (low severity noise)\r\n    // issues.push({\r\n    //   type: 'documentation',\r\n    //   message: 'Documentation file is too short',\r\n    //   line: 1,\r\n    //   severity: 'low',\r\n    //   source: 'doc-analyzer'\r\n    // });\r\n  }\r\n  \r\n  // REMOVED: Missing markdown headers (low severity noise)\r\n  // if (!/#+\\s/.test(content)) {\r\n  //   issues.push({\r\n  //     type: 'documentation',\r\n  //     message: 'Missing proper markdown headers',\r\n  //     line: 1,\r\n  //     severity: 'low',\r\n  //     source: 'doc-analyzer'\r\n  //   });\r\n  // }\r\n  \r\n  return issues;\r\n}\r\n\r\n// ðŸ“Š DATA FILE ANALYZER (Format & Structure)\r\nfunction analyzeDataFile(content, filePath, fileType) {\r\n  console.log(`ðŸ“Š Data file analysis: ${filePath}`);\r\n  \r\n  var issues = [];\r\n  var ext = path.extname(filePath);\r\n  \r\n  if (ext === '.json') {\r\n    try {\r\n      JSON.parse(content);\r\n    } catch (error) {\r\n      issues.push({\r\n        type: 'syntax',\r\n        message: 'Invalid JSON format: ' + error.message,\r\n        line: 1,\r\n        severity: 'high',\r\n        source: 'json-parser'\r\n      });\r\n    }\r\n  }\r\n  \r\n  return issues;\r\n}\r\n\r\n// ðŸŽ¯ SPECIALIZED HELPER FUNCTIONS\r\n\r\n// Get code patterns for specific subtypes\r\nfunction getCodePatterns(subtype) {\r\n  var patterns = {\r\n    react: [\r\n      { pattern: /useEffect\\s*\\(\\s*[^,]+\\s*\\)(?!\\s*,\\s*\\[)/, message: 'useEffect missing dependencies', severity: 'high' },\r\n      { pattern: /dangerouslySetInnerHTML/, message: 'XSS risk with dangerouslySetInnerHTML', severity: 'critical' },\r\n      { pattern: /useState\\(\\s*\\{\\s*\\}\\s*\\)/, message: 'useState with object - prefer useReducer', severity: 'medium' }\r\n    ],\r\n    backend: [\r\n      { pattern: /app\\.use\\([^)]*\\)(?!.*cors)/, message: 'Missing CORS middleware', severity: 'high' },\r\n      { pattern: /process\\.env\\.[A-Z_]+(?!\\s*\\|\\|)/, message: 'Missing environment variable fallback', severity: 'medium' },\r\n      { pattern: /\\.query\\s*\\(\\s*[\"`'][^\"`']*\\+/, message: 'SQL injection vulnerability', severity: 'critical' }\r\n    ],\r\n    ml: [\r\n      { pattern: /torch\\.load\\([^)]*\\)(?!.*map_location)/, message: 'PyTorch load without map_location', severity: 'medium' },\r\n      { pattern: /pickle\\.load/, message: 'Unsafe pickle.load usage', severity: 'high' },\r\n      { pattern: /eval\\s*\\(/, message: 'Dangerous eval() in ML code', severity: 'critical' }\r\n    ]\r\n  };\r\n  \r\n  return patterns[subtype] || [];\r\n}\r\n\r\n// Analyze with pattern matching\r\nfunction analyzeWithPatterns(content, patterns, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  patterns.forEach(function(pattern) {\r\n    lines.forEach(function(line, index) {\r\n      if (pattern.pattern.test(line)) {\r\n        issues.push({\r\n          type: 'pattern',\r\n          message: pattern.message,\r\n          line: index + 1,\r\n          code: line.trim(),\r\n          severity: pattern.severity,\r\n          source: 'pattern-matcher'\r\n        });\r\n      }\r\n    });\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// Package.json analyzer\r\nfunction analyzePackageJson(content, filePath) {\r\n  var issues = [];\r\n  \r\n  try {\r\n    var pkg = JSON.parse(content);\r\n    \r\n    // Security checks\r\n    if (!pkg.engines || !pkg.engines.node) {\r\n      issues.push({\r\n        type: 'config',\r\n        message: 'Missing Node.js engine specification',\r\n        line: 1,\r\n        severity: 'medium',\r\n        source: 'npm-analyzer'\r\n      });\r\n    }\r\n    \r\n    // Check for known vulnerable packages\r\n    var vulnerablePackages = ['lodash@4.17.20', 'moment@2.29.1', 'axios@0.21.0'];\r\n    Object.keys(pkg.dependencies || {}).forEach(function(dep) {\r\n      var version = pkg.dependencies[dep];\r\n      if (vulnerablePackages.some(vuln => vuln.startsWith(dep + '@'))) {\r\n        issues.push({\r\n          type: 'security',\r\n          message: `Potentially vulnerable package: ${dep}@${version}`,\r\n          line: findLineInJson(content, dep),\r\n          severity: 'high',\r\n          source: 'vulnerability-scanner'\r\n        });\r\n      }\r\n    });\r\n    \r\n  } catch (error) {\r\n    issues.push({\r\n      type: 'syntax',\r\n      message: 'Invalid package.json: ' + error.message,\r\n      line: 1,\r\n      severity: 'high',\r\n      source: 'json-parser'\r\n    });\r\n  }\r\n  \r\n  return issues;\r\n}\r\n\r\n// Environment file analyzer\r\nfunction analyzeEnvFile(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  lines.forEach(function(line, index) {\r\n    var trimmed = line.trim();\r\n    \r\n    // Check for exposed secrets\r\n    if (/^[A-Z_]+\\s*=\\s*[a-zA-Z0-9+/]{20,}/.test(trimmed)) {\r\n      issues.push({\r\n        type: 'security',\r\n        message: 'Potential secret in environment file',\r\n        line: index + 1,\r\n        code: trimmed.substring(0, 50) + '...',\r\n        severity: 'critical',\r\n        source: 'env-scanner'\r\n      });\r\n    }\r\n    \r\n    // Check for missing quotes\r\n    if (/=.*\\s/.test(trimmed) && !/=[\"']/.test(trimmed)) {\r\n      issues.push({\r\n        type: 'config',\r\n        message: 'Environment value with spaces should be quoted',\r\n        line: index + 1,\r\n        code: trimmed,\r\n        severity: 'medium',\r\n        source: 'env-scanner'\r\n      });\r\n    }\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// Dockerfile analyzer\r\nfunction analyzeDockerfile(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  lines.forEach(function(line, index) {\r\n    var trimmed = line.trim().toUpperCase();\r\n    \r\n    // Security best practices\r\n    if (trimmed.startsWith('FROM ') && trimmed.includes(':LATEST')) {\r\n      issues.push({\r\n        type: 'deployment',\r\n        message: 'Using :latest tag is not recommended',\r\n        line: index + 1,\r\n        code: line.trim(),\r\n        severity: 'medium',\r\n        source: 'docker-analyzer'\r\n      });\r\n    }\r\n    \r\n    if (trimmed.startsWith('RUN ') && trimmed.includes('SUDO')) {\r\n      issues.push({\r\n        type: 'security',\r\n        message: 'Avoid using sudo in Dockerfile',\r\n        line: index + 1,\r\n        code: line.trim(),\r\n        severity: 'high',\r\n        source: 'docker-analyzer'\r\n      });\r\n    }\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// Shell script analyzer\r\nfunction analyzeShellScript(content, filePath) {\r\n  var issues = [];\r\n  var lines = content.split('\\n');\r\n  \r\n  lines.forEach(function(line, index) {\r\n    var trimmed = line.trim();\r\n    \r\n    // Security checks\r\n    if (/\\$\\([^)]*\\)/.test(trimmed) && !/set -e/.test(content)) {\r\n      issues.push({\r\n        type: 'security',\r\n        message: 'Command substitution without error handling',\r\n        line: index + 1,\r\n        code: trimmed,\r\n        severity: 'medium',\r\n        source: 'shell-analyzer'\r\n      });\r\n    }\r\n  });\r\n  \r\n  return issues;\r\n}\r\n\r\n// Generic config analyzer\r\nfunction analyzeGenericConfig(content, filePath) {\r\n  var issues = [];\r\n  \r\n  // Check for common misconfigurations\r\n  if (/debug\\s*[:=]\\s*true/i.test(content)) {\r\n    issues.push({\r\n      type: 'config',\r\n      message: 'Debug mode enabled in configuration',\r\n      line: findLineNumber(content, /debug\\s*[:=]\\s*true/i),\r\n      severity: 'medium',\r\n      source: 'config-analyzer'\r\n    });\r\n  }\r\n  \r\n  return issues;\r\n}\r\n\r\n// Helper functions\r\nfunction findLineNumber(content, pattern) {\r\n  var lines = content.split('\\n');\r\n  for (var i = 0; i < lines.length; i++) {\r\n    if (pattern.test(lines[i])) {\r\n      return i + 1;\r\n    }\r\n  }\r\n  return 1;\r\n}\r\n\r\nfunction findLineInJson(content, key) {\r\n  var lines = content.split('\\n');\r\n  for (var i = 0; i < lines.length; i++) {\r\n    if (lines[i].includes('\"' + key + '\"')) {\r\n      return i + 1;\r\n    }\r\n  }\r\n  return 1;\r\n}\r\n\r\n// Enhance issues with metadata\r\nfunction enhanceIssuesWithMetadata(issues, fileType, content, filePath) {\r\n  return issues.map(function(issue) {\r\n    issue.fileType = fileType.category;\r\n    issue.subtype = fileType.subtype;\r\n    issue.priority = fileType.priority;\r\n    issue.confidence = issue.source === 'pattern-matcher' ? 'high' : 'medium';\r\n    return issue;\r\n  });\r\n}\r\n\r\n// ðŸš€ SMART BATCHING HELPER FUNCTIONS\r\n\r\n// Determine if a file will need AI analysis\r\nfunction willNeedAIAnalysis(content, filePath, classification) {\r\n  // Only CODE files might need AI\r\n  if (classification.category !== 'code') return false;\r\n  \r\n  // Large files likely need AI\r\n  if (content.length > 2000) return true;\r\n  \r\n  // Complex React components need AI\r\n  if (classification.subtype === 'react' && /useEffect|useContext|useReducer/i.test(content)) return true;\r\n  \r\n  // Backend files with auth/security need AI\r\n  if (classification.subtype === 'backend' && /auth|security|jwt|passport/i.test(content)) return true;\r\n  \r\n  // ML/AI files always need AI\r\n  if (classification.subtype === 'ml') return true;\r\n  \r\n  // Files with complex patterns need AI\r\n  if (/async.*await.*Promise|generator.*function|class.*extends/i.test(content)) return true;\r\n  \r\n  return false;\r\n}\r\n\r\n// FAST & SIMPLE batch sizing - prioritize speed over perfection\r\nfunction calculateAdaptiveBatchSize(totalFiles, batchNumber) {\r\n  // MUCH LARGER batches for speed - accept some timeout risk for performance\r\n  if (totalFiles < 500) {\r\n    return Math.min(100, totalFiles); // Small repos: 100 files per batch\r\n  } else if (totalFiles < 2000) {\r\n    return 150; // Medium repos: 150 files per batch\r\n  } else if (totalFiles < 10000) {\r\n    return 200; // Large repos: 200 files per batch  \r\n  } else {\r\n    // Huge repos: Still large batches for speed\r\n    return 250; // 250 files per batch = ~18 batches for React\r\n  }\r\n}\r\n\r\n// Enhanced file classification for batching\r\nfunction classifyFileForBatching(filePath, content) {\r\n  var classification = classifyFileType(filePath, content);\r\n  var needsAI = willNeedAIAnalysis(content, filePath, classification);\r\n  \r\n  return {\r\n    classification: classification,\r\n    needsAI: needsAI,\r\n    estimatedTime: needsAI ? '2-4s' : '0.1ms',\r\n    complexity: needsAI ? 'high' : 'low'\r\n  };\r\n}\r\n\r\n// Keep the old function for compatibility\r\nasync function generateCustomRules(repoContext) {\r\n  console.log('ðŸŽ¯ Using SPECIALIZED file-type analyzers with SMART BATCHING');\r\n  return null; // Signal to use specialized analysis\r\n}\r\n\r\n// ðŸš€ EXECUTE AI-GENERATED RULES ON ALL FILES\r\nasync function executeCustomRules(customRulesCode, filesToProcess, tempDir) {\r\n  try {\r\n    console.log(`âš¡ Executing AI-generated rules on ${filesToProcess.length} files...`);\r\n    \r\n    // SAFE EVALUATION: Use Function constructor instead of eval\r\n    var customRules;\r\n    try {\r\n      // Clean the code and wrap it properly\r\n      var cleanCode = customRulesCode\r\n        .replace(/```javascript/g, '')\r\n        .replace(/```js/g, '')\r\n        .replace(/```/g, '')\r\n        .trim();\r\n      \r\n      console.log(`ðŸ§¹ Cleaned code preview:`, cleanCode.substring(0, 200) + '...');\r\n      \r\n      // Validate basic structure before evaluation\r\n      if (!cleanCode.startsWith('{') || !cleanCode.endsWith('}')) {\r\n        throw new Error('Invalid JavaScript object structure');\r\n      }\r\n      \r\n      // Use Function constructor for safer evaluation\r\n      customRules = new Function('return ' + cleanCode)();\r\n      \r\n      if (!customRules.executeRules) {\r\n        throw new Error('Missing executeRules function');\r\n      }\r\n      \r\n      console.log('âœ… AI rules loaded successfully');\r\n      \r\n    } catch (evalError) {\r\n      console.error('âŒ Failed to evaluate AI-generated code:', evalError.message);\r\n      console.log('ðŸ” Problematic code snippet:', cleanCode.substring(0, 500) + '...');\r\n      return null;\r\n    }\r\n    \r\n    var results = [];\r\n    var totalIssues = 0;\r\n    \r\n    for (var i = 0; i < filesToProcess.length; i++) {\r\n      var file = filesToProcess[i];\r\n      try {\r\n        var content = await fs.readFile(file, 'utf-8');\r\n        var relativePath = path.relative(tempDir, file);\r\n        \r\n        // Execute AI-generated rules\r\n        var issues = customRules.executeRules(content, relativePath);\r\n        \r\n        if (issues && issues.length > 0) {\r\n          results.push({\r\n            file: relativePath,\r\n            issues: issues\r\n          });\r\n          totalIssues += issues.length;\r\n          \r\n          console.log(`ðŸ“ ${relativePath} â†’ ${issues.length} issues`);\r\n        }\r\n        \r\n      } catch (err) {\r\n        console.warn(`âš ï¸ Failed to analyze ${file}:`, err.message);\r\n      }\r\n    }\r\n    \r\n    console.log(`ðŸŽ‰ AI rules executed: ${totalIssues} issues found in ${results.length} files`);\r\n    return results;\r\n    \r\n  } catch (error) {\r\n    console.error('âŒ Rule execution failed:', error.message);\r\n    return null;\r\n  }\r\n}\r\n\r\nasync function findCodeFiles(dir) {\r\n  var files = [];\r\n  \r\n  // Priority file extensions - most important first\r\n  var highPriorityExts = ['.js', '.ts', '.jsx', '.tsx', '.py', '.java', '.go', '.rs'];\r\n  var mediumPriorityExts = ['.cpp', '.c', '.h', '.php', '.rb', '.swift', '.kt'];\r\n  var lowPriorityExts = ['.css', '.scss'];\r\n  \r\n  var allExts = highPriorityExts.concat(mediumPriorityExts, lowPriorityExts);\r\n  \r\n  // ALWAYS scan the entire repository (no directory filtering)\r\n  console.log('ðŸŒ Scanning ENTIRE repository for all code files...');\r\n  \r\n  try {\r\n    await scanDirectory(dir, files, allExts, 0);\r\n  } catch (error) {\r\n    console.warn(`Failed to scan directory ${dir}:`, error.message);\r\n  }\r\n  \r\n  // Sort by priority - NO LIMITS, return ALL files\r\n  var prioritizedFiles = [].concat(\r\n    files.filter(function(f) { return highPriorityExts.includes(path.extname(f).toLowerCase()); }),\r\n    files.filter(function(f) { return mediumPriorityExts.includes(path.extname(f).toLowerCase()); }),\r\n    files.filter(function(f) { return lowPriorityExts.includes(path.extname(f).toLowerCase()); })\r\n  );\r\n  \r\n  // Return ALL files - no limits for comprehensive analysis\r\n  console.log(`ðŸ“Š Final file count: ${prioritizedFiles.length} files for analysis`);\r\n  return prioritizedFiles;\r\n}\r\n\r\nasync function scanDirectory(dir, files, extensions, depth) {\r\n  // Prevent infinite recursion\r\n  if (depth > 10) return;\r\n  \r\n  try {\r\n    var items = await fs.readdir(dir, { withFileTypes: true });\r\n    \r\n    for (var i = 0; i < items.length; i++) {\r\n      var item = items[i];\r\n      // Skip common unimportant directories\r\n      if (item.name.startsWith('.') || \r\n          ['node_modules', 'build', 'dist', 'coverage', '__pycache__', 'target', 'vendor'].includes(item.name)) {\r\n        continue;\r\n      }\r\n      \r\n      var fullPath = path.join(dir, item.name);\r\n      \r\n      if (item.isDirectory()) {\r\n        await scanDirectory(fullPath, files, extensions, depth + 1);\r\n      } else if (item.isFile()) {\r\n        var ext = path.extname(item.name).toLowerCase();\r\n        if (extensions.includes(ext)) {\r\n          files.push(fullPath);\r\n        }\r\n      }\r\n    }\r\n  } catch (error) {\r\n    console.warn(`Failed to read directory ${dir}:`, error.message);\r\n  }\r\n}\r\n\r\nexport const handler = async (event) => {\r\n  console.log('ðŸ¤– CLEAN Lambda analyzer started:', JSON.stringify(event));\r\n  \r\n  var { repoUrl, analysisId, batchNumber = null, fullRepoAnalysis = false } = JSON.parse(event.body || '{}');\r\n  \r\n  if (!repoUrl || !analysisId) {\r\n    return {\r\n      statusCode: 400,\r\n      body: JSON.stringify({ error: 'repoUrl and analysisId required' })\r\n    };\r\n  }\r\n  \r\n  var tempDir = path.join('/tmp', `analysis-${Date.now()}`);\r\n  var results = [];\r\n  var isFileBatched = !!batchNumber;\r\n  \r\n  try {\r\n    // Step 1: ALWAYS SHALLOW CLONE FULL REPOSITORY\r\n    console.log(`ðŸ“¥ Shallow cloning full repository ${isFileBatched ? `(file batch ${batchNumber})` : '(single analysis)'}...`);\r\n    await fs.mkdir(tempDir, { recursive: true });\r\n    \r\n    // Try git layer first, fallback to system git\r\n    var gitPath = '/opt/bin/git'; // From git layer\r\n    try {\r\n      // Test if git layer exists\r\n      execSync(`${gitPath} --version`, { stdio: 'pipe' });\r\n      console.log('âœ… Using git from Lambda layer: /opt/bin/git');\r\n    } catch (error) {\r\n      console.warn('âš ï¸ Git layer not found, using system git');\r\n      gitPath = 'git';\r\n    }\r\n    \r\n    // Check available /tmp storage space\r\n    try {\r\n      var tmpStats = await fs.stat('/tmp');\r\n      console.log('ðŸ’¾ /tmp directory exists, checking available space...');\r\n      \r\n      // Get disk usage info (rough estimate)\r\n      var tmpUsage = execSync('df -h /tmp', { encoding: 'utf8' });\r\n      console.log('ðŸ’¾ /tmp storage info:', tmpUsage);\r\n    } catch (storageError) {\r\n      console.warn('âš ï¸ Could not check /tmp storage:', storageError.message);\r\n    }\r\n    \r\n    // REGULAR SHALLOW CLONE: Fast and reliable\r\n    console.log('ðŸŒŠ Performing shallow clone (depth=1)...');\r\n    \r\n    var cloneCmd = `${gitPath} clone --depth 1 --single-branch --no-tags \"${repoUrl}\" \"${tempDir}\"`;\r\n    console.log('ðŸ“‹ Clone command:', cloneCmd);\r\n    \r\n    try {\r\n      execSync(cloneCmd, { stdio: 'pipe' });\r\n      console.log('âœ… Shallow clone successful');\r\n    } catch (cloneError) {\r\n      console.error('âŒ Git clone failed:', cloneError.message);\r\n      console.error('ðŸ“‹ Failed command:', cloneCmd);\r\n      console.error('ðŸ” Repository URL:', repoUrl);\r\n      console.error('ðŸ“ Target directory:', tempDir);\r\n      throw new Error(`Failed to clone repository: ${cloneError.message}`);\r\n    }\r\n    \r\n    // Step 2: Find ALL code files from full repository\r\n    console.log('ðŸ“ Finding ALL code files from full repository...');\r\n    \r\n    var allFiles = await findCodeFiles(tempDir);\r\n    console.log(`ðŸ“Š CRITICAL: Found ${allFiles.length} total code files in repository`);\r\n    \r\n    // Step 3: Handle file-based batching\r\n    var filesToProcess = allFiles;\r\n    var isLastBatch = true;\r\n    \r\n    if (isFileBatched) {\r\n      // ðŸš€ ADAPTIVE BATCHING: Smart but lightweight approach\r\n      console.log('ðŸŽ¯ Using adaptive batching strategy...');\r\n      \r\n      // Determine batch size based on repository size and batch number\r\n      var adaptiveBatchSize = calculateAdaptiveBatchSize(allFiles.length, batchNumber);\r\n      console.log(`ðŸ“Š Adaptive batch size: ${adaptiveBatchSize} files`);\r\n      \r\n      const startIndex = (batchNumber - 1) * adaptiveBatchSize;\r\n      const endIndex = startIndex + adaptiveBatchSize;\r\n      \r\n      filesToProcess = allFiles.slice(startIndex, endIndex);\r\n      isLastBatch = endIndex >= allFiles.length || filesToProcess.length === 0;\r\n      \r\n      console.log(`ðŸ“¦ ADAPTIVE BATCH ${batchNumber} DETAILS:`);\r\n      console.log(`   ðŸ“Š Total files in repo: ${allFiles.length}`);\r\n      console.log(`   ðŸ“ Processing range: ${startIndex + 1} to ${Math.min(endIndex, allFiles.length)}`);\r\n      console.log(`   ðŸ“ Files in this batch: ${filesToProcess.length}`);\r\n      console.log(`   ðŸ Is last batch: ${isLastBatch}`);\r\n      \r\n      if (filesToProcess.length === 0) {\r\n        return {\r\n          statusCode: 200,\r\n          body: JSON.stringify({\r\n            success: true,\r\n            analysisId: analysisId,\r\n            results: [],\r\n            isFileBatched: true,\r\n            batchNumber: batchNumber,\r\n            isLastBatch: true,\r\n            stats: {\r\n              filesProcessed: 0,\r\n              filesWithIssues: 0,\r\n              totalIssues: 0,\r\n              totalFilesInRepo: allFiles.length\r\n            },\r\n            message: `ADAPTIVE BATCH ${batchNumber} - No more files to process`\r\n          })\r\n        };\r\n      }\r\n    }\r\n    \r\n    // Step 4: Analyze files using semantic bug detection (no timeouts for speed)\r\n    var processedFiles = 0;\r\n    var totalIssues = 0;\r\n    var batchStartTime = Date.now();\r\n    \r\n    for (var i = 0; i < filesToProcess.length; i++) {\r\n      var file = filesToProcess[i];\r\n      try {\r\n        var content = await fs.readFile(file, 'utf-8');\r\n        var relativePath = path.relative(tempDir, file);\r\n        \r\n        // ðŸŽ¯ SEMANTIC BUG DETECTION: Targeted analysis like real Greptile\r\n        var issues = await performSemanticBugDetection(content, relativePath, tempDir);\r\n        \r\n        processedFiles++;\r\n        \r\n        if (issues.length > 0) {\r\n          results.push({\r\n            file: relativePath,\r\n            issues: issues\r\n          });\r\n          totalIssues += issues.length;\r\n        }\r\n      } catch (err) {\r\n        console.warn(`âŒ Failed to analyze ${file}:`, err.message);\r\n        processedFiles++;\r\n      }\r\n    }\r\n    \r\n    console.log(`âœ… ANALYSIS COMPLETE FOR BATCH ${batchNumber || 'N/A'}:`);\r\n    console.log(`   ðŸ“Š Files processed: ${processedFiles}`);\r\n    console.log(`   ðŸ“ Files with issues: ${results.length}`);\r\n    console.log(`   ðŸš¨ Total issues found: ${totalIssues}`);\r\n    \r\n    // Note: AI filtering now happens in frontend API layer for better performance\r\n    \r\n    var returnData = {\r\n      success: true,\r\n      analysisId: analysisId,\r\n      results: results,\r\n      isFileBatched: isFileBatched,\r\n      batchNumber: batchNumber,\r\n      isLastBatch: isLastBatch,\r\n      stats: {\r\n        filesProcessed: processedFiles,\r\n        filesWithIssues: results.length,\r\n        totalIssues: totalIssues,\r\n        totalFilesInRepo: isFileBatched ? allFiles.length : processedFiles\r\n      },\r\n      message: `${isFileBatched ? `FILE BATCH ${batchNumber}` : 'FULL'} Analysis complete: ${totalIssues} issues found in ${results.length} files`\r\n    };\r\n    \r\n    return {\r\n      statusCode: 200,\r\n      body: JSON.stringify(returnData)\r\n    };\r\n    \r\n  } catch (error) {\r\n    console.error('âŒ Analysis failed:', error);\r\n    \r\n    return {\r\n      statusCode: 500,\r\n      body: JSON.stringify({\r\n        success: false,\r\n        error: error.message\r\n      })\r\n    };\r\n    \r\n  } finally {\r\n    // Cleanup\r\n    try {\r\n      execSync(`rm -rf \"${tempDir}\"`, { stdio: 'ignore' });\r\n    } catch (err) {\r\n      console.warn('Cleanup failed:', err.message);\r\n    }\r\n  }\r\n};\r\n"
  },
  "analysisDetails": {
    "patternsUsed": [],
    "functionsAnalyzed": [],
    "testingSteps": []
  },
  "issues": []
}
